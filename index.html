<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8" />
  <title>IBSTech Portal ‚Äì KI ¬∑ Robotik ¬∑ Embedded</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body { font-family: Arial, sans-serif; margin: 0; line-height: 1.6; color: #222; }
    header { background: #0b1b2b; color: #fff; padding: 40px 20px; text-align: center; }
    header h1 { margin: 0 0 5px; }
    header h2 { margin: 0 0 15px; font-weight: normal; font-size: 1.2rem; }
    header p { margin: 0 0 20px; max-width: 800px; margin-left: auto; margin-right: auto; }
    header a { display: inline-block; margin: 5px; padding: 10px 20px; border-radius: 4px; text-decoration: none; font-weight: bold; }
    .btn-primary { background: #ff8a00; color: #000; }
    .btn-secondary { border: 1px solid #fff; color: #fff; }

    nav {
      background: #111;
      color: #fff;
      padding: 10px 20px;
      position: sticky;
      top: 0;
      z-index: 10;
      display: flex;
      align-items: center;
      gap: 15px;
      flex-wrap: wrap;
    }
    .nav-links {
      display: flex;
      flex-wrap: wrap;
      gap: 15px;
    }
    nav a { color: #fff; text-decoration: none; font-size: 0.9rem; }
    nav a:hover { text-decoration: underline; }

    .lang-switcher {
      margin-left: auto;
      display: flex;
      gap: 6px;
      align-items: center;
    }
    .lang-switcher-label {
      font-size: 0.8rem;
      opacity: 0.7;
      margin-right: 4px;
    }
    .lang-btn {
      background: #222;
      border: 1px solid #444;
      border-radius: 4px;
      padding: 2px 6px;
      cursor: pointer;
      font-size: 1.1rem; /* Flaggen sch√∂n gro√ü */
      line-height: 1.2;
    }
    .lang-btn.active {
      border-color: #ff8a00;
      background: #333;
    }

    section { padding: 40px 20px; max-width: 1100px; margin: 0 auto; }
    h2 { margin-top: 0; color: #0b1b2b; }
    h3 { margin-bottom: 5px; }
    ul { padding-left: 20px; }

    .columns { display: flex; flex-wrap: wrap; gap: 20px; }
    .column { flex: 1 1 250px; border: 1px solid #ddd; padding: 20px; border-radius: 4px; background: #fafafa; }
    .badge { display: inline-block; padding: 3px 8px; font-size: 0.75rem; border-radius: 999px; background: #e3e7ef; color: #0b1b2b; margin-bottom: 5px; }

    footer { background: #0b1b2b; color: #fff; text-align: center; padding: 20px; font-size: 0.9rem; margin-top: 40px; }

    /* Vision / interaktives Schichtenbild */
    .vision-wrapper { margin-top: 20px; display: flex; flex-wrap: wrap; gap: 20px; }
    .vision-stack { flex: 1 1 100%; display: flex; flex-wrap: wrap; gap: 16px; align-items: stretch; }

    .vision-column {
      flex: 1 1 280px;
      border-radius: 10px;
      padding: 15px;
      background: linear-gradient(135deg, #f5f7fb, #e7ebf5);
      border: 1px solid #ccd2e0;
      transition: transform 0.15s ease, box-shadow 0.15s ease, border-color 0.15s ease;
      cursor: pointer;
      display: flex;
      flex-direction: column;
      justify-content: flex-start;
    }
    .vision-column:hover {
      transform: translateY(-4px);
      box-shadow: 0 8px 18px rgba(0,0,0,0.12);
      border-color: #ff8a00;
    }
    .vision-column h3 { margin-top: 0; margin-bottom: 4px; text-align: center; }
    .vision-tagline { font-size: 0.85rem; color: #555; margin-bottom: 10px; text-align: center; }

    .layer-list {
      list-style: none;
      padding-left: 0;
      margin: 0;
      font-size: 0.85rem;
      display: flex;
      flex-direction: column;
      gap: 4px;
    }
    .layer-list li {
      background: rgba(255,255,255,0.95);
      border-radius: 4px;
      border: 1px solid #d2d7e5;
      padding: 4px 8px;
      box-shadow: 0 1px 2px rgba(0,0,0,0.05);
      text-align: center;
    }

    .vision-info {
      margin-top: 24px;
      padding: 15px 20px;
      border-radius: 8px;
      border: 1px solid #ccd2e0;
      background: #f6f8fc;
    }
    .vision-info h3 { margin-top: 0; margin-bottom: 5px; }
    .vision-info p { margin: 0; font-size: 0.9rem; }

    /* Domain-Tags unter dem Hero */
    .domain-tags { margin-top: 10px; font-size: 0.85rem; }
    .domain-tag {
      display: inline-block;
      margin: 2px 4px;
      padding: 3px 8px;
      border-radius: 999px;
      border: 1px solid rgba(255,255,255,0.5);
      color: #f0f4ff;
      background: rgba(0,0,0,0.15);
    }

    /* Demo-KI-Agent (Chat-Widget) */
    .chat-widget {
      position: fixed;
      bottom: 20px;
      right: 20px;
      width: 320px;
      max-width: 90%;
      background: #ffffff;
      border-radius: 10px;
      box-shadow: 0 8px 20px rgba(0,0,0,0.25);
      display: flex;
      flex-direction: column;
      overflow: hidden;
      font-size: 0.9rem;
      z-index: 999;
    }
    .chat-header {
      background: #0b1b2b;
      color: #fff;
      padding: 8px 12px;
      display: flex;
      justify-content: space-between;
      align-items: center;
      cursor: pointer; /* gesamter Header klickbar */
    }
    .chat-header span {
      font-weight: bold;
    }
    .chat-toggle {
      cursor: pointer;
      font-size: 0.9rem;
      opacity: 0.8;
    }
    .chat-body {
      background: #f6f8fc;
      max-height: 260px;
      overflow-y: auto;
      padding: 8px 10px;
    }
    .chat-input {
      border-top: 1px solid #ccd2e0;
      padding: 6px;
      background: #eef1f8;
      display: flex;
      gap: 6px;
    }
    .chat-input input {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
      border: 1px solid #ccd2e0;
      font-size: 0.9rem;
    }
    .chat-input button {
      padding: 6px 10px;
      border-radius: 4px;
      border: none;
      background: #ff8a00;
      color: #000;
      font-weight: bold;
      cursor: pointer;
      font-size: 0.85rem;
    }
    .chat-message {
      margin: 4px 0;
      display: flex;
    }
    .chat-message.user {
      justify-content: flex-end;
    }
    .chat-bubble {
      max-width: 80%;
      padding: 6px 8px;
      border-radius: 8px;
    }
    .chat-message.user .chat-bubble {
      background: #ffedd5;
      align-self: flex-end;
    }
    .chat-message.agent .chat-bubble {
      background: #ffffff;
      border: 1px solid #dde3f0;
    }
    .chat-widget.collapsed .chat-body,
    .chat-widget.collapsed .chat-input {
      display: none;
    }
    .chat-widget.collapsed {
      width: 220px;
    }

    /* Gef√ºhrte Sensorsohlen-Demo */
    .demo-walkthrough {
      margin-top: 30px;
      padding: 20px;
      border-radius: 10px;
      border: 1px solid #dde1ec;
      background: #f7f8fd;
    }
    .demo-walkthrough h3 {
      margin-top: 0;
      margin-bottom: 10px;
    }
    .demo-steps {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      margin-bottom: 15px;
    }
    .demo-step-btn {
      flex: 1 1 120px;
      min-width: 120px;
      padding: 6px 10px;
      border-radius: 999px;
      border: 1px solid #c4c9dd;
      background: #ffffff;
      font-size: 0.85rem;
      cursor: pointer;
      text-align: center;
      transition: background 0.15s ease, border-color 0.15s ease, transform 0.1s ease;
    }
    .demo-step-btn span.step-number {
      font-weight: bold;
      margin-right: 4px;
    }
    .demo-step-btn:hover {
      background: #ffedd5;
      border-color: #ff8a00;
      transform: translateY(-1px);
    }
    .demo-step-btn.active {
      background: #ff8a00;
      border-color: #ff8a00;
      color: #000;
      font-weight: bold;
    }

    .demo-content {
      display: flex;
      flex-direction: column;
      gap: 10px;
    }
    .demo-image-wrapper {
      width: 100%;
      border-radius: 8px;
      overflow: hidden;
      background: #e5e8f3;
      border: 1px solid #ccd2e0;
    }
    .demo-image-wrapper img {
      display: block;
      max-width: 100%;
      height: auto;
    }
    .demo-text {
      font-size: 0.9rem;
    }
    .demo-text h4 {
      margin: 0 0 4px;
      color: #0b1b2b;
    }
    .demo-text p {
      margin: 0;
    }

    @media (max-width: 600px) {
      header { padding: 30px 15px; }
      section { padding: 30px 15px; }
      nav { padding: 10px 12px; }
      .nav-links { gap: 10px; }
      .lang-switcher { margin-left: 0; margin-top: 6px; }
    }
  </style>
</head>
<body>

  <nav>
    <div class="nav-links">
      <a href="#home" id="nav-home-link">Home</a>
      <a href="#vision" id="nav-vision-link">Digitaler Zwilling &amp; Schichtenbild</a>
      <a href="#tools" id="nav-tools-link">Tools</a>
      <a href="#demos" id="nav-demos-link">Demos</a>
      <a href="#links" id="nav-links-link">Links</a>
      <a href="#events" id="nav-events-link">Events</a>
    </div>
    <div class="lang-switcher">
      <span class="lang-switcher-label">Sprache:</span>
      <button class="lang-btn active" data-lang="de" aria-label="Deutsch">üá©üá™</button>
      <button class="lang-btn" data-lang="en" aria-label="English">üá¨üáß</button>
      <button class="lang-btn" data-lang="fr" aria-label="Fran√ßais">üá´üá∑</button>
      <button class="lang-btn" data-lang="es" aria-label="Espa√±ol (Ecuador)">üá™üá®</button>
    </div>
  </nav>

  <header id="home">
    <h1 id="hero-title">IBSTech Portal</h1>
    <h2 id="hero-tagline">KI ¬∑ Robotik ¬∑ Embedded</h2>
    <p id="hero-subtitle">Digitaler Zwilling und Simulation von KI-, Robotik- und Embedded-Systemen.</p>
    <div class="domain-tags">
      <span class="domain-tag">MedTech</span>
      <span class="domain-tag">Robotik</span>
      <span class="domain-tag">Automotive</span>
      <span class="domain-tag">Industrie&nbsp;4.0</span>
      <span class="domain-tag">IoT &amp; Smart Home</span>
      <span class="domain-tag">Kommunikation &amp; Edge</span>
    </div>
    <br />
    <a href="#vision" class="btn-primary" id="btn-vision">Digitaler Zwilling &amp; Schichtenbild</a>
    <a href="#demos" class="btn-secondary" id="btn-demos">Demos ansehen</a>
  </header>

  <section id="vision">
    <h2 id="vision-title">Digitaler Zwilling &amp; interaktives Schichtenbild</h2>

    <h3 id="vision-video-title">Video: Digitaler Zwilling des klassischen Stacks</h3>
    <p id="vision-video-text">Dieses Video zeigt den klassischen Stack als digitales Haus ‚Äì von Cloud bis Hardware &amp; Sensorik.</p>
    <video width="100%" controls>
      <source src="DigitalerZwilling.mp4" type="video/mp4" />
      Dein Browser unterst√ºtzt das Video-Tag nicht.
    </video>

    <p>
      <a id="vision-youtube-link" href="https://youtu.be/zUHOcTU51rM" target="_blank" rel="noopener noreferrer">
        Video auf YouTube ansehen
      </a>
    </p>

    <hr style="margin:30px 0; border:none; border-top:1px solid #ddd;" />

    <h3 id="vision-stack-title">Interaktives Schichtenbild</h3>
    <p id="vision-stack-text">Bewege die Maus √ºber eine der drei S√§ulen, um den jeweiligen Ansatz zu erkl√§ren.</p>

    <div class="vision-wrapper">
      <div class="vision-stack">
        <!-- Links: klassischer Stack -->
        <div class="vision-column"
             data-title="Klassischer Stack"
             data-description="Viele Schichten, viel Handarbeit: jede Ebene separat modelliert, programmiert und integriert. Hoher Aufwand, aber maximale Kontrolle.">
          <h3 id="vision-col-today">Heute</h3>
          <div class="vision-tagline" id="vision-col-today-tagline">klassischer Stack</div>
          <ul class="layer-list">
            <li>Cloud / Backend</li>
            <li>Edge-Gateway / Middleware</li>
            <li>Robotik-Logik &amp; Regelung</li>
            <li>Firmware (RTOS, Protokolle)</li>
            <li>Hardware &amp; Sensorik</li>
          </ul>
        </div>

        <!-- Mitte: Hybrid -->
        <div class="vision-column"
             style="border-color:#ff8a00; background:linear-gradient(135deg,#fff7ec,#ffe0b8);"
             data-title="Hybrid: Mensch + KI"
             data-description="Embedded, Robotik und KI arbeiten zusammen: KI unterst√ºtzt Sensorfusion, Anomalieerkennung und Planung, w√§hrend Echtzeit und Safety in klaren Schichten bleiben.">
          <h3 id="vision-col-middle">Mitte</h3>
          <div class="vision-tagline" id="vision-col-middle-tagline">Hybrid ‚Äì Mensch + KI</div>
          <ul class="layer-list">
            <li>Cloud (Training, Flottenanalyse)</li>
            <li>Edge-AI &amp; Koordination</li>
            <li>Robotik-Planung + Controller</li>
            <li>On-Device-ML &amp; Firmware</li>
            <li>Hardware, Aktoren &amp; Sensoren</li>
          </ul>
        </div>

        <!-- Rechts: KI-dominierte Zukunft -->
        <div class="vision-column"
             data-title="KI-dominierte Systeme"
             data-description="Stark automatisierte Pipelines: KI-Agenten √ºbernehmen gro√üe Teile von Design, Planung und Steuerung. Effizient, aber mit hohem Bedarf an Erkl√§rbarkeit und Governance.">
          <h3 id="vision-col-future">Zukunft</h3>
          <div class="vision-tagline" id="vision-col-future-tagline">KI-√ºbersteuerter Stack</div>
          <ul class="layer-list">
            <li>End-to-End KI-Orchestrierung</li>
            <li>Auto-Generierung von Code &amp; Tests</li>
            <li>Selbstoptimierende Regelung</li>
            <li>Generische Runtime-Plattform</li>
            <li>Sensoren &amp; Aktoren als ‚ÄûRessourcen‚Äú</li>
          </ul>
        </div>
      </div>
    </div>

    <div class="vision-info" id="vision-info">
      <h3 class="vision-info-title" id="vision-info-title">Hinweis</h3>
      <p class="vision-info-text" id="vision-info-text">
        Fahre mit der Maus √ºber ‚ÄûHeute‚Äú, ‚ÄûMitte‚Äú oder ‚ÄûZukunft‚Äú, um den jeweiligen Ansatz kurz erkl√§rt zu bekommen.
        Das l√§sst sich in der Pr√§sentation sehr gut live kommentieren.
      </p>
    </div>
  </section>

  <section id="tools">
    <h2 id="tools-title">Tools ‚Äì KI ¬∑ Robotik ¬∑ Embedded</h2>
    <div class="columns">
      <div class="column">
        <span class="badge" id="tools-card1-badge">Embedded-KI</span>
        <h3 id="tools-card1-title">Edge-AI Toolchain (Konzept)</h3>
        <p id="tools-card1-text">
          Pipeline von Datenerfassung √ºber Feature-Engineering bis zur Modellintegration auf Mikrocontrollern
          (z. B. f√ºr MedTech, Automotive oder IoT).
        </p>
      </div>
      <div class="column">
        <span class="badge" id="tools-card2-badge">Robotik</span>
        <h3 id="tools-card2-title">Robotik-Stack-Templates</h3>
        <p id="tools-card2-text">
          Vorlagen f√ºr Robotik-Anwendungen mit klarer Trennung von Echtzeit-Controllern,
          Bewegungsplanung und KI-gest√ºtzter Wahrnehmung.
        </p>
      </div>
      <div class="column">
        <span class="badge" id="tools-card3-badge">Prototyping</span>
        <h3 id="tools-card3-title">Prototyping-Templates</h3>
        <p id="tools-card3-text">
          Projekt-Templates f√ºr schnelle Demos ‚Äì z. B. Zustands√ºberwachung, Ganganalyse,
          smarte Aktorik ‚Äì inklusive Visualisierung und Datenaufzeichnung.
        </p>
      </div>
    </div>
  </section>

  <section id="demos">
    <h2 id="demos-title">Demos ‚Äì KI in Aktion</h2>
    <p id="demos-intro-text">Beispiele, die sich live zeigen lassen (MedTech, Industrie, Robotik, IoT).</p>

    <!-- Gef√ºhrte Demo Sensorsohlen -->
    <div class="demo-walkthrough" id="sensor-walkthrough">
      <h3 id="walk-title">Demo: Sensorsohlen ‚Äì Ganganalyse (6-Schritte-√úbersicht)</h3>
      <p id="walk-intro-text" style="font-size:0.9rem;">
        Klicke dich Schritt f√ºr Schritt durch das System ‚Äì von der Produkt√ºbersicht √ºber Hardware und Software bis zum fertigen Analysebericht.
      </p>

      <div class="demo-steps">
        <button class="demo-step-btn active" data-step="0">
          <span class="step-number">1</span>
          <span id="step-label-0">Produkt√ºbersicht</span>
        </button>
        <button class="demo-step-btn" data-step="1">
          <span class="step-number">2</span>
          <span id="step-label-1">Schaltplan</span>
        </button>
        <button class="demo-step-btn" data-step="2">
          <span class="step-number">3</span>
          <span id="step-label-2">Systemarchitektur</span>
        </button>
        <button class="demo-step-btn" data-step="3">
          <span class="step-number">4</span>
          <span id="step-label-3">Softwarearchitektur</span>
        </button>
        <button class="demo-step-btn" data-step="4">
          <span class="step-number">5</span>
          <span id="step-label-4">Bericht ‚Äì √úbersicht</span>
        </button>
        <button class="demo-step-btn" data-step="5">
          <span class="step-number">6</span>
          <span id="step-label-5">Bericht ‚Äì Details</span>
        </button>
      </div>

      <div class="demo-content">
        <div class="demo-image-wrapper">
          <img id="demo-image" src="media/sohle_1_produkt.jpeg" alt="Sensorsohlen Produkt√ºbersicht" />
        </div>
        <div class="demo-text">
          <h4 id="demo-title">Schritt 1: Produkt√ºbersicht</h4>
          <p id="demo-description">
            Die Sensorsohlen bestehen aus zwei Einlagen mit integrierter Elektronik im Kunststoffgeh√§use.
            Jede Einlage sitzt zwischen Ferse und Mittelfu√ü, misst Druckverl√§ufe und Bewegung und kommuniziert per BLE mit der App.
          </p>
        </div>
      </div>
    </div>

    <hr style="margin:30px 0; border:none; border-top:1px solid #ddd;" />

    <!-- Bestehende Demo-Beschreibungen -->
    <h3 id="further-demos-title">Weitere Demo-Ideen</h3>
    <h4 id="further-demo1-title">Ganzheitliche Physio- &amp; Reha-Analyse</h4>
    <ul>
      <li>Sensorsohlen mit Druck- und IMU-Sensoren (Ganganalyse).</li>
      <li>Video- &amp; 3D-K√∂rperanalyse (markerlose Pose-Estimation).</li>
      <li>EMG-Biofeedback f√ºr Muskelaktivit√§t und Kompensationsmuster.</li>
      <li>KI-Fusion f√ºr Kennzahlen, Alerts und Therapie-Empfehlungen.</li>
    </ul>

    <h4 id="further-demo2-title">KI-Zustands√ºberwachung eines Antriebs (Industrie/IoT)</h4>
    <ul>
      <li>Sensorknoten mit IMU, Temperatur und Stromsensor.</li>
      <li>Edge-AI f√ºr Merkmalsextraktion und Zustandsbewertung.</li>
      <li>Dashboard-Visualisierung, optional Feldbus/MQTT-Anbindung.</li>
    </ul>
  </section>

  <section id="links">
    <h2 id="links-title">Links ‚Äì Podcasts, Seiten, Repos</h2>
    <p id="links-intro-text">Struktur f√ºr sp√§tere Inhalte (aktuell Platzhalter).</p>
    <div class="columns">
      <div class="column">
        <h3>Podcasts</h3>
        <ul>
          <li>Embedded-Entwicklung &amp; Echtzeit (Platzhalter)</li>
          <li>KI in Industrie &amp; Robotik (Platzhalter)</li>
        </ul>
      </div>
      <div class="column">
        <h3>Webseiten &amp; Blogs</h3>
        <ul>
          <li>Edge-AI / TinyML (Platzhalter)</li>
          <li>Robotik-Architekturen mit KI (Platzhalter)</li>
        </ul>
      </div>
      <div class="column">
        <h3>Repos &amp; Dokus</h3>
        <ul>
          <li>Open-Source-Beispiele f√ºr Embedded-KI (Platzhalter)</li>
          <li>Dokumentation zu Toolchains &amp; Frameworks (Platzhalter)</li>
        </ul>
      </div>
    </div>
  </section>

  <section id="events">
    <h2 id="events-title">Events ‚Äì Konferenzen, Meetups, Schulungen</h2>
    <p id="events-intro-text">Platzhalter f√ºr zuk√ºnftige Veranstaltungen rund um KI, Robotik und Embedded.</p>
    <ul>
      <li>Embedded-KI-Workshop (Idee).</li>
      <li>Robotik &amp; KI-Demo-Tag (Idee).</li>
      <li>Community-Meetup KI &amp; Embedded (Idee).</li>
    </ul>
  </section>

  <footer>
    ¬© IBSTech Portal ‚Äì KI ¬∑ Robotik ¬∑ Embedded
  </footer>

  <!-- Demo-KI-Agent (einfacher Browser-Chat) -->
  <div class="chat-widget collapsed" id="demo-agent">
    <div class="chat-header" id="chat-header">
      <span>Demo-KI-Agent</span>
      <span class="chat-toggle" id="chat-toggle">‚ñ≤</span>
    </div>
    <div class="chat-body" id="chat-log">
      <div class="chat-message agent">
        <div class="chat-bubble">
          Hallo, ich bin der Demo-Agent.<br />
          Frag mich z.B. nach <strong>heute</strong>, <strong>hybrid</strong>, <strong>zukunft</strong>,
          oder nach den <strong>Demos</strong> (Physio, Antrieb).
        </div>
      </div>
    </div>
    <div class="chat-input">
      <input type="text" id="chat-input-text" placeholder="Frage eingeben ..." />
      <button id="chat-send">Senden</button>
    </div>
  </div>

  <script>
    // Interaktives Schichtenbild
    (function() {
      var infoBox = document.getElementById('vision-info');
      if (!infoBox) return;
      var titleEl = infoBox.querySelector('.vision-info-title');
      var textEl = infoBox.querySelector('.vision-info-text');
      var columns = document.querySelectorAll('.vision-column');

      columns.forEach(function(col) {
        col.addEventListener('mouseenter', function() {
          var t = col.getAttribute('data-title') || '';
          var d = col.getAttribute('data-description') || '';
          if (t) titleEl.textContent = t;
          if (d) textEl.textContent = d;
        });
        col.setAttribute('tabindex', '0');
        col.addEventListener('focus', function() {
          var t = col.getAttribute('data-title') || '';
          var d = col.getAttribute('data-description') || '';
          if (t) titleEl.textContent = t;
          if (d) textEl.textContent = d;
        });
      });
    })();
  </script>

  <script>
    // Demo-KI-Agent (einfacher Browser-Chat)
    (function() {
      const widget = document.getElementById('demo-agent');
      const toggle = document.getElementById('chat-toggle');
      const header = document.getElementById('chat-header');
      const log = document.getElementById('chat-log');
      const input = document.getElementById('chat-input-text');
      const sendBtn = document.getElementById('chat-send');

      if (!widget || !toggle || !log || !input || !sendBtn || !header) return;

      function toggleChat() {
        widget.classList.toggle('collapsed');
        toggle.textContent = widget.classList.contains('collapsed') ? '‚ñ≤' : '‚ñº';
      }

      // gesamter Header (Titel + Pfeil) ist klickbar
      header.addEventListener('click', toggleChat);

      function appendMessage(text, from) {
        const msg = document.createElement('div');
        msg.className = 'chat-message ' + (from === 'user' ? 'user' : 'agent');
        const bubble = document.createElement('div');
        bubble.className = 'chat-bubble';
        bubble.innerHTML = text;
        msg.appendChild(bubble);
        log.appendChild(msg);
        log.scrollTop = log.scrollHeight;
      }

      function generateAgentAnswer(question) {
        const q = question.toLowerCase();

        if (q.includes('heute') || q.includes('klassisch')) {
          return 'Im klassischen Stack ist alles stark getrennt: Hardware & Sensorik unten, dann Firmware mit RTOS und Protokollen, dar√ºber Robotik-Logik und Regelung, ein Edge-Gateway und ganz oben Cloud/Backend. Viel Handarbeit, aber volle Kontrolle.';
        }
        if (q.includes('hybrid') || q.includes('mitte')) {
          return 'Im Hybrid-Ansatz bleibt die klassische Struktur erhalten, aber einzelne Schichten werden von KI unterst√ºtzt ‚Äì zum Beispiel Sensorfusion, Anomalieerkennung oder Bewegungsplanung. Echtzeit und Safety bleiben klar abgetrennt.';
        }
        if (q.includes('zukunft') || q.includes('ki-domin')) {
          return 'In KI-dominierten Systemen √ºbernehmen KI-Agenten gro√üe Teile von Design, Planung und Steuerung. Das kann sehr effizient sein, braucht aber starke Mechanismen f√ºr Erkl√§rbarkeit, Safety und Governance.';
        }
        if (q.includes('physio') || q.includes('reha')) {
          return 'Die Physio-/Reha-Demo kombiniert Sensorsohlen, Video- und 3D-Analyse sowie EMG-Biofeedback. Ziel ist eine durchg√§ngige Analyse von Gangbild und Bewegung f√ºr Pr√§vention, Assessment und Reha.';
        }
        if (q.includes('antrieb') || q.includes('motor') || q.includes('zustands')) {
          return 'Die Zustands√ºberwachungs-Demo nutzt Vibration, Strom und Temperatur an einem Antrieb. Embedded-KI erkennt Abweichungen fr√ºhzeitig und kann so auf Wartungsbedarf oder Fehlzust√§nde hinweisen.';
        }
        if (q.includes('multi-agent') || q.includes('agenten')) {
          return 'Multi-Agent-Orchestrierung bedeutet, dass spezialisierte KI-Agenten entlang des V-Modells helfen: bei Anforderungen, Architektur, Code, Tests und Betrieb. Jeder Agent hat eine klare Rolle, der Mensch bleibt in der Verantwortung.';
        }
        if (q.includes('video') || q.includes('digitaler zwilling')) {
          return 'Das Video zeigt den klassischen Stack als digitalen Zwilling in Form eines Hauses ‚Äì von Cloud/Backend oben bis Hardware & Sensorik unten. Es ist die visuelle Basis, um sp√§ter Hybrid- und Zukunftsszenarien zu erkl√§ren.';
        }

        return 'Ich habe deine Frage verstanden, aber ich bin nur ein einfacher Demo-Agent im Browser. Versuche es mal mit Stichw√∂rtern wie ‚Äûheute‚Äú, ‚Äûhybrid‚Äú, ‚Äûzukunft‚Äú, ‚ÄûPhysio‚Äú, ‚ÄûAntrieb‚Äú oder ‚ÄûMulti-Agent‚Äú.';
      }

      function handleSend() {
        const text = input.value.trim();
        if (!text) return;
        appendMessage(text, 'user');
        input.value = '';

        const answer = generateAgentAnswer(text);
        setTimeout(function() {
          appendMessage(answer, 'agent');
        }, 300);
      }

      sendBtn.addEventListener('click', handleSend);
      input.addEventListener('keydown', function(e) {
        if (e.key === 'Enter') {
          handleSend();
        }
      });
    })();
  </script>

  <script>
    // Mehrsprachigkeit + gef√ºhrte Sensorsohlen-Demo
    (function() {
      const stepMeta = [
        { img: 'media/sohle_1_produkt.jpeg', key: 'step1' },
        { img: 'media/sohle_2_schaltplan.jpg', key: 'step2' },
        { img: 'media/sohle_3_systemarchitektur.jpg', key: 'step3' },
        { img: 'media/sohle_4_softwarearchitektur.jpg', key: 'step4' },
        { img: 'media/sohle_5_bericht1.png', key: 'step5' },
        { img: 'media/sohle_6_bericht2.png', key: 'step6' }
      ];

      const translations = {
        de: {
          texts: {
            'nav-home-link': 'Home',
            'nav-vision-link': 'Digitaler Zwilling & Schichtenbild',
            'nav-tools-link': 'Tools',
            'nav-demos-link': 'Demos',
            'nav-links-link': 'Links',
            'nav-events-link': 'Events',

            'hero-title': 'IBSTech Portal',
            'hero-tagline': 'KI ¬∑ Robotik ¬∑ Embedded',
            'hero-subtitle': 'Digitaler Zwilling und Simulation von KI-, Robotik- und Embedded-Systemen.',
            'btn-vision': 'Digitaler Zwilling & Schichtenbild',
            'btn-demos': 'Demos ansehen',

            'vision-title': 'Digitaler Zwilling & interaktives Schichtenbild',
            'vision-video-title': 'Video: Digitaler Zwilling des klassischen Stacks',
            'vision-video-text': 'Dieses Video zeigt den klassischen Stack als digitales Haus ‚Äì von Cloud bis Hardware & Sensorik.',
            'vision-youtube-link': 'Video auf YouTube ansehen',
            'vision-stack-title': 'Interaktives Schichtenbild',
            'vision-stack-text': 'Bewege die Maus √ºber eine der drei S√§ulen, um den jeweiligen Ansatz zu erkl√§ren.',
            'vision-col-today': 'Heute',
            'vision-col-today-tagline': 'klassischer Stack',
            'vision-col-middle': 'Mitte',
            'vision-col-middle-tagline': 'Hybrid ‚Äì Mensch + KI',
            'vision-col-future': 'Zukunft',
            'vision-col-future-tagline': 'KI-√ºbersteuerter Stack',
            'vision-info-title': 'Hinweis',
            'vision-info-text': 'Fahre mit der Maus √ºber ‚ÄûHeute‚Äú, ‚ÄûMitte‚Äú oder ‚ÄûZukunft‚Äú, um den jeweiligen Ansatz kurz erkl√§rt zu bekommen. Das l√§sst sich in der Pr√§sentation sehr gut live kommentieren.',

            'tools-title': 'Tools ‚Äì KI ¬∑ Robotik ¬∑ Embedded',
            'tools-card1-badge': 'Embedded-KI',
            'tools-card1-title': 'Edge-AI Toolchain (Konzept)',
            'tools-card1-text': 'Pipeline von Datenerfassung √ºber Feature-Engineering bis zur Modellintegration auf Mikrocontrollern (z. B. f√ºr MedTech, Automotive oder IoT).',
            'tools-card2-badge': 'Robotik',
            'tools-card2-title': 'Robotik-Stack-Templates',
            'tools-card2-text': 'Vorlagen f√ºr Robotik-Anwendungen mit klarer Trennung von Echtzeit-Controllern, Bewegungsplanung und KI-gest√ºtzter Wahrnehmung.',
            'tools-card3-badge': 'Prototyping',
            'tools-card3-title': 'Prototyping-Templates',
            'tools-card3-text': 'Projekt-Templates f√ºr schnelle Demos ‚Äì z. B. Zustands√ºberwachung, Ganganalyse, smarte Aktorik ‚Äì inklusive Visualisierung und Datenaufzeichnung.',

            'demos-title': 'Demos ‚Äì KI in Aktion',
            'demos-intro-text': 'Beispiele, die sich live zeigen lassen (MedTech, Industrie, Robotik, IoT).',
            'walk-title': 'Demo: Sensorsohlen ‚Äì Ganganalyse (6-Schritte-√úbersicht)',
            'walk-intro-text': 'Klicke dich Schritt f√ºr Schritt durch das System ‚Äì von der Produkt√ºbersicht √ºber Hardware und Software bis zum fertigen Analysebericht.',

            'step-label-0': 'Produkt√ºbersicht',
            'step-label-1': 'Schaltplan',
            'step-label-2': 'Systemarchitektur',
            'step-label-3': 'Softwarearchitektur',
            'step-label-4': 'Bericht ‚Äì √úbersicht',
            'step-label-5': 'Bericht ‚Äì Details',

            'further-demos-title': 'Weitere Demo-Ideen',
            'further-demo1-title': 'Ganzheitliche Physio- & Reha-Analyse',
            'further-demo2-title': 'KI-Zustands√ºberwachung eines Antriebs (Industrie/IoT)',

            'links-title': 'Links ‚Äì Podcasts, Seiten, Repos',
            'links-intro-text': 'Struktur f√ºr sp√§tere Inhalte (aktuell Platzhalter).',

            'events-title': 'Events ‚Äì Konferenzen, Meetups, Schulungen',
            'events-intro-text': 'Platzhalter f√ºr zuk√ºnftige Veranstaltungen rund um KI, Robotik und Embedded.'
          },
          steps: {
            step1: {
              label: 'Produkt√ºbersicht',
              title: 'Schritt 1: Produkt√ºbersicht',
              desc: 'Die Sensorsohlen bestehen aus zwei Einlagen mit integrierter Elektronik im Kunststoffgeh√§use. Jede Einlage sitzt zwischen Ferse und Mittelfu√ü, misst Druckverl√§ufe und Bewegung und kommuniziert per BLE mit der App.'
            },
            step2: {
              label: 'Schaltplan',
              title: 'Schritt 2: Schaltplan der Elektronik',
              desc: 'Der Schaltplan zeigt LiPo-Akku, Schutzschaltung, LDO, MCU mit BLE, IMU sowie mehrere Drucksensoren (FSR) als Spannungsteiler auf ADC-Kan√§len. So entsteht die lokale Mess- und Funkplattform in der Sohle.'
            },
            step3: {
              label: 'Systemarchitektur',
              title: 'Schritt 3: Systemarchitektur',
              desc: 'Die Systemarchitektur verbindet die beiden Sensorsohlen √ºber BLE mit der Smartphone-App und weiter mit einem Cloud-/Backend-System. Dort werden Daten gespeichert, analysiert und f√ºr Reports aufbereitet.'
            },
            step4: {
              label: 'Softwarearchitektur',
              title: 'Schritt 4: Softwarearchitektur',
              desc: 'Die Softwarearchitektur zeigt die Ebenen von der Firmware auf der Sohle (Treiber, RTOS, Messlogik) √ºber BLE-Protokoll und Smartphone-App (UI, Domain-Logik) bis hin zur Analyse-Engine und dem Report-Generator im Backend.'
            },
            step5: {
              label: 'Bericht ‚Äì √úbersicht',
              title: 'Schritt 5: Analysebericht ‚Äì √úbersicht',
              desc: 'Der erste Berichtsscreen zeigt die wichtigsten Kennzahlen wie Symmetrie, Cadence und Speed sowie aggregierte Bewertungen. Er dient als schneller √úberblick f√ºr Nutzer und Therapeuten.'
            },
            step6: {
              label: 'Bericht ‚Äì Details',
              title: 'Schritt 6: Analysebericht ‚Äì Details',
              desc: 'Im Detailbericht werden zus√§tzliche Parameter wie Gait Line, Pronation/Supination, Belastungsverl√§ufe und Clearance visualisiert. Das erlaubt eine tiefergehende Interpretation des Gangbilds.'
            }
          }
        },

        en: {
          texts: {
            'nav-home-link': 'Home',
            'nav-vision-link': 'Digital twin & layer view',
            'nav-tools-link': 'Tools',
            'nav-demos-link': 'Demos',
            'nav-links-link': 'Links',
            'nav-events-link': 'Events',

            'hero-title': 'IBSTech Portal',
            'hero-tagline': 'AI ¬∑ Robotics ¬∑ Embedded',
            'hero-subtitle': 'Digital twin and simulation of AI, robotics and embedded systems.',
            'btn-vision': 'Digital twin & layer view',
            'btn-demos': 'View demos',

            'vision-title': 'Digital twin & interactive layer model',
            'vision-video-title': 'Video: Digital twin of the classic stack',
            'vision-video-text': 'This video shows the classic stack as a digital house ‚Äì from cloud down to hardware & sensors.',
            'vision-youtube-link': 'Watch video on YouTube',
            'vision-stack-title': 'Interactive layer view',
            'vision-stack-text': 'Move the mouse over one of the three pillars to see the respective approach explained.',
            'vision-col-today': 'Today',
            'vision-col-today-tagline': 'classic stack',
            'vision-col-middle': 'Middle',
            'vision-col-middle-tagline': 'Hybrid ‚Äì human + AI',
            'vision-col-future': 'Future',
            'vision-col-future-tagline': 'AI-driven stack',
            'vision-info-title': 'Hint',
            'vision-info-text': 'Hover over ‚ÄúToday‚Äù, ‚ÄúMiddle‚Äù or ‚ÄúFuture‚Äù to get a short explanation of each approach. This works very well for live commentary in your presentation.',

            'tools-title': 'Tools ‚Äì AI ¬∑ Robotics ¬∑ Embedded',
            'tools-card1-badge': 'Embedded AI',
            'tools-card1-title': 'Edge-AI toolchain (concept)',
            'tools-card1-text': 'Pipeline from data acquisition and feature engineering to model integration on microcontrollers (e.g. for MedTech, automotive or IoT).',
            'tools-card2-badge': 'Robotics',
            'tools-card2-title': 'Robotics stack templates',
            'tools-card2-text': 'Templates for robotics applications with a clear separation between real-time controllers, motion planning and AI-based perception.',
            'tools-card3-badge': 'Prototyping',
            'tools-card3-title': 'Prototyping templates',
            'tools-card3-text': 'Project templates for fast demos ‚Äì e.g. condition monitoring, gait analysis, smart actuators ‚Äì including visualization and data logging.',

            'demos-title': 'Demos ‚Äì AI in action',
            'demos-intro-text': 'Examples that can be shown live (MedTech, industry, robotics, IoT).',
            'walk-title': 'Demo: sensor insoles ‚Äì gait analysis (6-step overview)',
            'walk-intro-text': 'Click through the system step by step ‚Äì from product overview via hardware and software to the final analysis report.',

            'step-label-0': 'Product overview',
            'step-label-1': 'Schematic',
            'step-label-2': 'System architecture',
            'step-label-3': 'Software architecture',
            'step-label-4': 'Report ‚Äì overview',
            'step-label-5': 'Report ‚Äì details',

            'further-demos-title': 'Additional demo ideas',
            'further-demo1-title': 'Holistic physio & rehab analysis',
            'further-demo2-title': 'AI-based drive condition monitoring (industry/IoT)',

            'links-title': 'Links ‚Äì podcasts, pages, repos',
            'links-intro-text': 'Structure for future content (currently placeholders).',

            'events-title': 'Events ‚Äì conferences, meetups, trainings',
            'events-intro-text': 'Placeholder for future events around AI, robotics and embedded.'
          },
          steps: {
            step1: {
              label: 'Product overview',
              title: 'Step 1: Product overview',
              desc: 'The sensor insoles consist of two inserts with integrated electronics in a plastic housing. Each insert sits between heel and midfoot, measures pressure patterns and motion, and communicates via BLE with the app.'
            },
            step2: {
              label: 'Schematic',
              title: 'Step 2: Electronics schematic',
              desc: 'The schematic shows LiPo battery, protection circuit, LDO, MCU with BLE, IMU and multiple pressure sensors (FSR) as voltage dividers on ADC channels. This forms the local measurement and radio platform inside the insole.'
            },
            step3: {
              label: 'System architecture',
              title: 'Step 3: System architecture',
              desc: 'The system architecture connects both sensor insoles via BLE to the smartphone app and further to a cloud/backend system. Data is stored, analysed and prepared for reports there.'
            },
            step4: {
              label: 'Software architecture',
              title: 'Step 4: Software architecture',
              desc: 'The software architecture spans from firmware on the insole (drivers, RTOS, measurement logic) via BLE protocol and smartphone app (UI, domain logic) up to the analytics engine and report generator in the backend.'
            },
            step5: {
              label: 'Report ‚Äì overview',
              title: 'Step 5: Analysis report ‚Äì overview',
              desc: 'The first report screen shows key metrics such as symmetry, cadence and speed plus aggregated ratings. It provides a quick overview for users and therapists.'
            },
            step6: {
              label: 'Report ‚Äì details',
              title: 'Step 6: Analysis report ‚Äì details',
              desc: 'The detailed report visualises additional parameters such as gait line, pronation/supination, load curves and clearance. This enables deeper interpretation of the gait pattern.'
            }
          }
        },

        fr: {
          texts: {
            'nav-home-link': 'Accueil',
            'nav-vision-link': 'Jumeau num√©rique & couches',
            'nav-tools-link': 'Outils',
            'nav-demos-link': 'D√©mos',
            'nav-links-link': 'Liens',
            'nav-events-link': '√âv√©nements',

            'hero-title': 'IBSTech Portal',
            'hero-tagline': 'IA ¬∑ Robotique ¬∑ Embarqu√©',
            'hero-subtitle': 'Jumeau num√©rique et simulation de syst√®mes IA, robotiques et embarqu√©s.',
            'btn-vision': 'Jumeau num√©rique & couches',
            'btn-demos': 'Voir les d√©mos',

            'vision-title': 'Jumeau num√©rique & vue en couches interactive',
            'vision-video-title': 'Vid√©o : jumeau num√©rique de la pile classique',
            'vision-video-text': 'Cette vid√©o montre la pile classique sous forme de maison num√©rique ‚Äì du cloud jusqu‚Äôau mat√©riel et aux capteurs.',
            'vision-youtube-link': 'Voir la vid√©o sur YouTube',
            'vision-stack-title': 'Vue en couches interactive',
            'vision-stack-text': 'Survolez l‚Äôune des trois colonnes pour voir l‚Äôapproche correspondante expliqu√©e.',
            'vision-col-today': 'Aujourd‚Äôhui',
            'vision-col-today-tagline': 'pile classique',
            'vision-col-middle': 'Milieu',
            'vision-col-middle-tagline': 'Hybride ‚Äì humain + IA',
            'vision-col-future': 'Futur',
            'vision-col-future-tagline': 'Pile pilot√©e par l‚ÄôIA',
            'vision-info-title': 'Remarque',
            'vision-info-text': 'Survolez ¬´ Aujourd‚Äôhui ¬ª, ¬´ Milieu ¬ª ou ¬´ Futur ¬ª pour obtenir une courte explication de chaque approche. Id√©al √† commenter en direct pendant la pr√©sentation.',

            'tools-title': 'Outils ‚Äì IA ¬∑ Robotique ¬∑ Embarqu√©',
            'tools-card1-badge': 'IA embarqu√©e',
            'tools-card1-title': 'Toolchain Edge-AI (concept)',
            'tools-card1-text': 'Pipeline allant de l‚Äôacquisition des donn√©es et l‚Äôing√©nierie des caract√©ristiques jusqu‚Äô√† l‚Äôint√©gration du mod√®le sur microcontr√¥leurs (p. ex. pour MedTech, automobile ou IoT).',
            'tools-card2-badge': 'Robotique',
            'tools-card2-title': 'Templates de pile robotique',
            'tools-card2-text': 'Mod√®les pour des applications robotiques avec s√©paration claire entre contr√¥le temps r√©el, planification de mouvement et perception bas√©e sur l‚ÄôIA.',
            'tools-card3-badge': 'Prototypage',
            'tools-card3-title': 'Templates de prototypage',
            'tools-card3-text': 'Templates de projet pour des d√©mos rapides ‚Äì p. ex. surveillance d‚Äô√©tat, analyse de marche, actionneurs intelligents ‚Äì y compris visualisation et enregistrement des donn√©es.',

            'demos-title': 'D√©mos ‚Äì l‚ÄôIA en action',
            'demos-intro-text': 'Exemples √† montrer en direct (MedTech, industrie, robotique, IoT).',
            'walk-title': 'D√©mo : semelles capteurs ‚Äì analyse de marche (vue en 6 √©tapes)',
            'walk-intro-text': 'Parcourez le syst√®me √©tape par √©tape ‚Äì de la vue produit au mat√©riel et logiciel jusqu‚Äôau rapport d‚Äôanalyse final.',

            'step-label-0': 'Vue produit',
            'step-label-1': 'Sch√©ma',
            'step-label-2': 'Architecture syst√®me',
            'step-label-3': 'Architecture logicielle',
            'step-label-4': 'Rapport ‚Äì vue d‚Äôensemble',
            'step-label-5': 'Rapport ‚Äì d√©tails',

            'further-demos-title': 'Autres id√©es de d√©mos',
            'further-demo1-title': 'Analyse physio & r√©√©ducation globale',
            'further-demo2-title': 'Surveillance d‚Äô√©tat de moteur par IA (industrie/IoT)',

            'links-title': 'Liens ‚Äì podcasts, sites, repos',
            'links-intro-text': 'Structure pour du contenu futur (pour l‚Äôinstant des espaces r√©serv√©s).',

            'events-title': '√âv√©nements ‚Äì conf√©rences, meetups, formations',
            'events-intro-text': 'Espace r√©serv√© pour de futurs √©v√©nements autour de l‚ÄôIA, de la robotique et de l‚Äôembarqu√©.'
          },
          steps: {
            step1: {
              label: 'Vue produit',
              title: '√âtape 1 : vue produit',
              desc: 'Les semelles capteurs se composent de deux inserts avec √©lectronique int√©gr√©e dans un bo√Ætier plastique. Chaque insert se trouve entre le talon et le m√©dio-pied, mesure les profils de pression et le mouvement et communique en BLE avec l‚Äôapplication.'
            },
            step2: {
              label: 'Sch√©ma',
              title: '√âtape 2 : sch√©ma √©lectronique',
              desc: 'Le sch√©ma montre une batterie LiPo, un circuit de protection, un LDO, un MCU avec BLE, une IMU ainsi que plusieurs capteurs de pression (FSR) en diviseurs de tension sur des entr√©es ADC. Cela forme la plateforme locale de mesure et de radio dans la semelle.'
            },
            step3: {
              label: 'Architecture syst√®me',
              title: '√âtape 3 : architecture syst√®me',
              desc: 'L‚Äôarchitecture syst√®me relie les deux semelles capteurs via BLE √† l‚Äôapplication smartphone puis √† un backend/cloud. Les donn√©es y sont stock√©es, analys√©es et pr√©par√©es pour les rapports.'
            },
            step4: {
              label: 'Architecture logicielle',
              title: '√âtape 4 : architecture logicielle',
              desc: 'L‚Äôarchitecture logicielle couvre le firmware sur la semelle (drivers, RTOS, logique de mesure), le protocole BLE et l‚Äôapplication smartphone (UI, logique m√©tier) jusqu‚Äôau moteur d‚Äôanalyse et au g√©n√©rateur de rapports dans le backend.'
            },
            step5: {
              label: 'Rapport ‚Äì vue d‚Äôensemble',
              title: '√âtape 5 : rapport d‚Äôanalyse ‚Äì vue d‚Äôensemble',
              desc: 'Le premier √©cran de rapport affiche les principaux indicateurs comme la sym√©trie, la cadence et la vitesse ainsi que des √©valuations agr√©g√©es. Il fournit une vue rapide pour les utilisateurs et les th√©rapeutes.'
            },
            step6: {
              label: 'Rapport ‚Äì d√©tails',
              title: '√âtape 6 : rapport d‚Äôanalyse ‚Äì d√©tails',
              desc: 'Le rapport d√©taill√© visualise des param√®tres suppl√©mentaires comme la ligne de marche, la pronation/supination, les courbes de charge et la clearance. Cela permet une interpr√©tation plus approfondie de la marche.'
            }
          }
        },

        es: {
          texts: {
            'nav-home-link': 'Inicio',
            'nav-vision-link': 'Gemelo digital y capas',
            'nav-tools-link': 'Herramientas',
            'nav-demos-link': 'Demos',
            'nav-links-link': 'Enlaces',
            'nav-events-link': 'Eventos',

            'hero-title': 'IBSTech Portal',
            'hero-tagline': 'IA ¬∑ Rob√≥tica ¬∑ Embebido',
            'hero-subtitle': 'Gemelo digital y simulaci√≥n de sistemas de IA, rob√≥tica y embebidos.',
            'btn-vision': 'Gemelo digital y capas',
            'btn-demos': 'Ver demos',

            'vision-title': 'Gemelo digital y vista por capas interactiva',
            'vision-video-title': 'V√≠deo: gemelo digital del stack cl√°sico',
            'vision-video-text': 'Este v√≠deo muestra el stack cl√°sico como una casa digital, desde la nube hasta el hardware y los sensores.',
            'vision-youtube-link': 'Ver v√≠deo en YouTube',
            'vision-stack-title': 'Vista por capas interactiva',
            'vision-stack-text': 'Mueve el rat√≥n sobre una de las tres columnas para ver explicada cada aproximaci√≥n.',
            'vision-col-today': 'Hoy',
            'vision-col-today-tagline': 'stack cl√°sico',
            'vision-col-middle': 'Centro',
            'vision-col-middle-tagline': 'H√≠brido ‚Äì humano + IA',
            'vision-col-future': 'Futuro',
            'vision-col-future-tagline': 'Stack dirigido por IA',
            'vision-info-title': 'Nota',
            'vision-info-text': 'Pasa el rat√≥n por ¬´Hoy¬ª, ¬´Centro¬ª o ¬´Futuro¬ª para obtener una breve explicaci√≥n de cada enfoque. Es ideal para comentarlo en directo durante la presentaci√≥n.',

            'tools-title': 'Herramientas ‚Äì IA ¬∑ Rob√≥tica ¬∑ Embebido',
            'tools-card1-badge': 'IA embebida',
            'tools-card1-title': 'Toolchain de Edge-AI (concepto)',
            'tools-card1-text': 'Pipeline desde la adquisici√≥n de datos y el dise√±o de caracter√≠sticas hasta la integraci√≥n del modelo en microcontroladores (p. ej. para MedTech, automoci√≥n o IoT).',
            'tools-card2-badge': 'Rob√≥tica',
            'tools-card2-title': 'Plantillas de stack rob√≥tico',
            'tools-card2-text': 'Modelos para aplicaciones rob√≥ticas con clara separaci√≥n entre control en tiempo real, planificaci√≥n de movimiento y percepci√≥n basada en IA.',
            'tools-card3-badge': 'Prototipado',
            'tools-card3-title': 'Plantillas de prototipado',
            'tools-card3-text': 'Plantillas de proyecto para demos r√°pidas ‚Äì p. ej. monitorizaci√≥n de estado, an√°lisis de la marcha, actuadores inteligentes ‚Äì con visualizaci√≥n y registro de datos.',

            'demos-title': 'Demos ‚Äì IA en acci√≥n',
            'demos-intro-text': 'Ejemplos que se pueden mostrar en directo (MedTech, industria, rob√≥tica, IoT).',
            'walk-title': 'Demo: plantillas sensoras ‚Äì an√°lisis de la marcha (vista en 6 pasos)',
            'walk-intro-text': 'Recorre el sistema paso a paso: desde la vista del producto, pasando por hardware y software, hasta el informe de an√°lisis final.',

            'step-label-0': 'Vista del producto',
            'step-label-1': 'Esquema',
            'step-label-2': 'Arquitectura del sistema',
            'step-label-3': 'Arquitectura de software',
            'step-label-4': 'Informe ‚Äì resumen',
            'step-label-5': 'Informe ‚Äì detalles',

            'further-demos-title': 'M√°s ideas de demos',
            'further-demo1-title': 'An√°lisis global de fisio y rehabilitaci√≥n',
            'further-demo2-title': 'Monitorizaci√≥n de estado de un accionamiento con IA (industria/IoT)',

            'links-title': 'Enlaces ‚Äì podcasts, sitios, repos',
            'links-intro-text': 'Estructura para contenido futuro (de momento marcadores de posici√≥n).',

            'events-title': 'Eventos ‚Äì conferencias, meetups, formaciones',
            'events-intro-text': 'Marcador de posici√≥n para futuros eventos sobre IA, rob√≥tica y embebidos.'
          },
          steps: {
            step1: {
              label: 'Vista del producto',
              title: 'Paso 1: vista del producto',
              desc: 'Las plantillas sensoras constan de dos plantillas con electr√≥nica integrada en una carcasa de pl√°stico. Cada plantilla se sit√∫a entre el tal√≥n y el mediopi√©, mide patrones de presi√≥n y movimiento y se comunica por BLE con la app.'
            },
            step2: {
              label: 'Esquema',
              title: 'Paso 2: esquema electr√≥nico',
              desc: 'El esquema muestra una bater√≠a LiPo, circuito de protecci√≥n, LDO, MCU con BLE, IMU y varios sensores de presi√≥n (FSR) como divisores de tensi√≥n en canales ADC. Esto forma la plataforma local de medida y radio dentro de la plantilla.'
            },
            step3: {
              label: 'Arquitectura del sistema',
              title: 'Paso 3: arquitectura del sistema',
              desc: 'La arquitectura del sistema conecta las dos plantillas sensoras mediante BLE con la app del smartphone y despu√©s con un sistema backend/nube. All√≠ se almacenan, analizan y preparan los datos para los informes.'
            },
            step4: {
              label: 'Arquitectura de software',
              title: 'Paso 4: arquitectura de software',
              desc: 'La arquitectura de software cubre el firmware en la plantilla (drivers, RTOS, l√≥gica de medida), el protocolo BLE y la app del smartphone (UI, l√≥gica de dominio) hasta el motor de anal√≠tica y el generador de informes en el backend.'
            },
            step5: {
              label: 'Informe ‚Äì resumen',
              title: 'Paso 5: informe de an√°lisis ‚Äì resumen',
              desc: 'La primera pantalla del informe muestra m√©tricas clave como simetr√≠a, cadencia y velocidad, adem√°s de valoraciones agregadas. Ofrece una visi√≥n r√°pida para usuarios y terapeutas.'
            },
            step6: {
              label: 'Informe ‚Äì detalles',
              title: 'Paso 6: informe de an√°lisis ‚Äì detalles',
              desc: 'El informe detallado visualiza par√°metros adicionales como l√≠nea de marcha, pronaci√≥n/supinaci√≥n, curvas de carga y clearance. Esto permite una interpretaci√≥n m√°s profunda del patr√≥n de marcha.'
            }
          }
        }
      };

      let currentLang = 'de';
      let currentStepIndex = 0;

      const imgEl = document.getElementById('demo-image');
      const titleEl = document.getElementById('demo-title');
      const descEl = document.getElementById('demo-description');
      const buttons = document.querySelectorAll('.demo-step-btn');

      function setStep(index) {
        const meta = stepMeta[index];
        if (!meta) return;
        const dictSteps = translations[currentLang].steps;
        const stepTexts = dictSteps[meta.key];
        imgEl.src = meta.img;
        imgEl.alt = stepTexts.title;
        titleEl.textContent = stepTexts.title;
        descEl.textContent = stepTexts.desc;

        buttons.forEach(btn => btn.classList.remove('active'));
        const active = Array.from(buttons).find(b => Number(b.getAttribute('data-step')) === index);
        if (active) active.classList.add('active');

        currentStepIndex = index;
      }

      buttons.forEach(btn => {
        btn.addEventListener('click', () => {
          const index = Number(btn.getAttribute('data-step'));
          setStep(index);
        });
      });

      function applyTranslations() {
        const dict = translations[currentLang];
        if (!dict) return;

        // statische Texte
        Object.keys(dict.texts).forEach(id => {
          const el = document.getElementById(id);
          if (el) {
            el.textContent = dict.texts[id];
          }
        });

        // Schritt-Labels
        stepMeta.forEach((meta, idx) => {
          const labelEl = document.getElementById('step-label-' + idx);
          if (!labelEl) return;
          const stepTexts = dict.steps[meta.key];
          labelEl.textContent = stepTexts.label;
        });

        // Sprache im <html>-Tag setzen
        document.documentElement.lang = currentLang;

        // Aktiven Button markieren
        document.querySelectorAll('.lang-btn').forEach(btn => {
          btn.classList.toggle('active', btn.getAttribute('data-lang') === currentLang);
        });

        // aktuellen Schritt-Text aktualisieren
        setStep(currentStepIndex);
      }

      // Sprachbuttons
      document.querySelectorAll('.lang-btn').forEach(btn => {
        btn.addEventListener('click', () => {
          const lang = btn.getAttribute('data-lang');
          if (!translations[lang]) return;
          currentLang = lang;
          applyTranslations();
        });
      });

      // Initiale Sprache anwenden
      applyTranslations();
    })();
  </script>

</body>
</html>
