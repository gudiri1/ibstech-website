<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8" />
  <title>IBSTech Portal – KI · Robotik · Embedded</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body { font-family: Arial, sans-serif; margin: 0; line-height: 1.6; color: #222; }
    header { background: #0b1b2b; color: #fff; padding: 40px 20px; text-align: center; }
    header h1 { margin: 0 0 5px; }
    header h2 { margin: 0 0 15px; font-weight: normal; font-size: 1.2rem; }
    header p { margin: 0 0 20px; max-width: 800px; margin-left: auto; margin-right: auto; }
    header a { display: inline-block; margin: 5px; padding: 10px 20px; border-radius: 4px; text-decoration: none; font-weight: bold; }
    .btn-primary { background: #ff8a00; color: #000; }
    .btn-secondary { border: 1px solid #fff; color: #fff; }

    nav {
      background: #111;
      color: #fff;
      padding: 10px 20px;
      position: sticky;
      top: 0;
      z-index: 10;
      display: flex;
      align-items: center;
      gap: 15px;
      flex-wrap: wrap;
    }
    .nav-links {
      display: flex;
      flex-wrap: wrap;
      gap: 15px;
    }
    nav a { color: #fff; text-decoration: none; font-size: 0.9rem; }
    nav a:hover { text-decoration: underline; }

    .lang-switcher {
      margin-left: auto;
      display: flex;
      gap: 6px;
      align-items: center;
    }
    .lang-switcher-label {
      font-size: 0.8rem;
      opacity: 0.7;
      margin-right: 4px;
    }
    .lang-btn {
      background: #222;
      border: 1px solid #444;
      border-radius: 4px;
      padding: 2px 4px;
      cursor: pointer;
    }
    .lang-btn.active {
      border-color: #ff8a00;
      background: #333;
    }
    .lang-btn img.flag-icon {
      display: block;
      width: 22px;
      height: auto;
    }

    section { padding: 40px 20px; max-width: 1100px; margin: 0 auto; }
    h2 { margin-top: 0; color: #0b1b2b; }
    h3 { margin-bottom: 5px; }
    ul { padding-left: 20px; }

    .columns { display: flex; flex-wrap: wrap; gap: 20px; }
    .column { flex: 1 1 250px; border: 1px solid #ddd; padding: 20px; border-radius: 4px; background: #fafafa; }
    .badge { display: inline-block; padding: 3px 8px; font-size: 0.75rem; border-radius: 999px; background: #e3e7ef; color: #0b1b2b; margin-bottom: 5px; }

    footer { background: #0b1b2b; color: #fff; text-align: center; padding: 20px; font-size: 0.9rem; margin-top: 40px; }

    /* Vision / interaktives Schichtenbild */
    .vision-wrapper { margin-top: 20px; display: flex; flex-wrap: wrap; gap: 20px; }
    .vision-stack { flex: 1 1 100%; display: flex; flex-wrap: wrap; gap: 16px; align-items: stretch; }

    .vision-column {
      flex: 1 1 280px;
      border-radius: 10px;
      padding: 15px;
      background: linear-gradient(135deg, #f5f7fb, #e7ebf5);
      border: 1px solid #ccd2e0;
      transition: transform 0.15s ease, box-shadow 0.15s ease, border-color 0.15s ease;
      cursor: pointer;
      display: flex;
      flex-direction: column;
      justify-content: flex-start;
    }
    .vision-column:hover {
      transform: translateY(-4px);
      box-shadow: 0 8px 18px rgba(0,0,0,0.12);
      border-color: #ff8a00;
    }
    .vision-column h3 { margin-top: 0; margin-bottom: 4px; text-align: center; }
    .vision-tagline { font-size: 0.85rem; color: #555; margin-bottom: 10px; text-align: center; }

    .layer-list {
      list-style: none;
      padding-left: 0;
      margin: 0;
      font-size: 0.85rem;
      display: flex;
      flex-direction: column;
      gap: 4px;
    }
    .layer-list li {
      background: rgba(255,255,255,0.95);
      border-radius: 4px;
      border: 1px solid #d2d7e5;
      padding: 4px 8px;
      box-shadow: 0 1px 2px rgba(0,0,0,0.05);
      text-align: center;
    }

    .vision-info {
      margin-top: 24px;
      padding: 15px 20px;
      border-radius: 8px;
      border: 1px solid #ccd2e0;
      background: #f6f8fc;
    }
    .vision-info h3 { margin-top: 0; margin-bottom: 5px; }
    .vision-info p { margin: 0; font-size: 0.9rem; }

    /* Domain-Tags unter dem Hero */
    .domain-tags { margin-top: 10px; font-size: 0.85rem; }
    .domain-tag {
      display: inline-block;
      margin: 2px 4px;
      padding: 3px 8px;
      border-radius: 999px;
      border: 1px solid rgba(255,255,255,0.5);
      color: #f0f4ff;
      background: rgba(0,0,0,0.15);
    }

    /* Demo-KI-Agent (Chat-Widget) */
    .chat-widget {
      position: fixed;
      bottom: 20px;
      right: 20px;
      width: 320px;
      max-width: 90%;
      background: #ffffff;
      border-radius: 10px;
      box-shadow: 0 8px 20px rgba(0,0,0,0.25);
      display: flex;
      flex-direction: column;
      overflow: hidden;
      font-size: 0.9rem;
      z-index: 999;
    }
    .chat-header {
      background: #0b1b2b;
      color: #fff;
      padding: 8px 12px;
      display: flex;
      justify-content: space-between;
      align-items: center;
      cursor: pointer; /* gesamter Header klickbar */
    }
    .chat-header span {
      font-weight: bold;
    }
    .chat-toggle {
      cursor: pointer;
      font-size: 0.9rem;
      opacity: 0.8;
    }
    .chat-body {
      background: #f6f8fc;
      max-height: 260px;
      overflow-y: auto;
      padding: 8px 10px;
    }
    .chat-input {
      border-top: 1px solid #ccd2e0;
      padding: 6px;
      background: #eef1f8;
      display: flex;
      gap: 6px;
    }
    .chat-input input {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
      border: 1px solid #ccd2e0;
      font-size: 0.9rem;
    }
    .chat-input button {
      padding: 6px 10px;
      border-radius: 4px;
      border: none;
      background: #ff8a00;
      color: #000;
      font-weight: bold;
      cursor: pointer;
      font-size: 0.85rem;
    }
    .chat-message {
      margin: 4px 0;
      display: flex;
    }
    .chat-message.user {
      justify-content: flex-end;
    }
    .chat-bubble {
      max-width: 80%;
      padding: 6px 8px;
      border-radius: 8px;
    }
    .chat-message.user .chat-bubble {
      background: #ffedd5;
      align-self: flex-end;
    }
    .chat-message.agent .chat-bubble {
      background: #ffffff;
      border: 1px solid #dde3f0;
    }
    .chat-widget.collapsed .chat-body,
    .chat-widget.collapsed .chat-input {
      display: none;
    }
    .chat-widget.collapsed {
      width: 220px;
    }

    /* Geführte Sensorsohlen-Demo */
    .demo-walkthrough {
      margin-top: 30px;
      padding: 20px;
      border-radius: 10px;
      border: 1px solid #dde1ec;
      background: #f7f8fd;
    }
    .demo-walkthrough h3 {
      margin-top: 0;
      margin-bottom: 10px;
    }
    .demo-steps {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      margin-bottom: 15px;
    }
    .demo-step-btn {
      flex: 1 1 120px;
      min-width: 120px;
      padding: 6px 10px;
      border-radius: 999px;
      border: 1px solid #c4c9dd;
      background: #ffffff;
      font-size: 0.85rem;
      cursor: pointer;
      text-align: center;
      transition: background 0.15s ease, border-color 0.15s ease, transform 0.1s ease;
    }
    .demo-step-btn span.step-number {
      font-weight: bold;
      margin-right: 4px;
    }
    .demo-step-btn:hover {
      background: #ffedd5;
      border-color: #ff8a00;
      transform: translateY(-1px);
    }
    .demo-step-btn.active {
      background: #ff8a00;
      border-color: #ff8a00;
      color: #000;
      font-weight: bold;
    }

    .demo-content {
      display: flex;
      flex-direction: column;
      gap: 10px;
    }
    .demo-image-wrapper {
      width: 100%;
      border-radius: 8px;
      overflow: hidden;
      background: #e5e8f3;
      border: 1px solid #ccd2e0;
    }
    .demo-image-wrapper img {
      display: block;
      max-width: 100%;
      height: auto;
    }
    .demo-text {
      font-size: 0.9rem;
    }
    .demo-text h4 {
      margin: 0 0 4px;
      color: #0b1b2b;
    }
    .demo-text p {
      margin: 0;
    }

    @media (max-width: 600px) {
      header { padding: 30px 15px; }
      section { padding: 30px 15px; }
      nav { padding: 10px 12px; }
      .nav-links { gap: 10px; }
      .lang-switcher { margin-left: 0; margin-top: 6px; }
    }
  </style>
</head>
<body>

  <nav>
    <div class="nav-links">
      <a href="#home" id="nav-home-link">Home</a>
      <a href="#vision" id="nav-vision-link">Digitaler Zwilling &amp; Schichtenbild</a>
      <a href="#tools" id="nav-tools-link">Tools</a>
      <a href="#demos" id="nav-demos-link">Demos</a>
      <a href="#links" id="nav-links-link">Links</a>
      <a href="#events" id="nav-events-link">Events</a>
    </div>
    <div class="lang-switcher">
      <span class="lang-switcher-label">Sprache:</span>
      <button class="lang-btn active" data-lang="de" aria-label="Deutsch">
        <img src="media/flag_de.png" alt="Deutsch" class="flag-icon" />
      </button>
      <button class="lang-btn" data-lang="en" aria-label="English">
        <img src="media/flag_gb.png" alt="English" class="flag-icon" />
      </button>
      <button class="lang-btn" data-lang="fr" aria-label="Français">
        <img src="media/flag_fr.png" alt="Français" class="flag-icon" />
      </button>
      <button class="lang-btn" data-lang="es" aria-label="Español (Ecuador)">
        <img src="media/flag_ec.png" alt="Español (Ecuador)" class="flag-icon" />
      </button>
    </div>
  </nav>

  <header id="home">
    <h1 id="hero-title">IBSTech Portal</h1>
    <h2 id="hero-tagline">KI · Robotik · Embedded</h2>
    <p id="hero-subtitle">Digitaler Zwilling und Simulation von KI-, Robotik- und Embedded-Systemen.</p>
    <div class="domain-tags">
      <span class="domain-tag">MedTech</span>
      <span class="domain-tag">Robotik</span>
      <span class="domain-tag">Automotive</span>
      <span class="domain-tag">Industrie&nbsp;4.0</span>
      <span class="domain-tag">IoT &amp; Smart Home</span>
      <span class="domain-tag">Kommunikation &amp; Edge</span>
    </div>
    <br />
    <a href="#vision" class="btn-primary" id="btn-vision">Digitaler Zwilling &amp; Schichtenbild</a>
    <a href="#demos" class="btn-secondary" id="btn-demos">Demos ansehen</a>
  </header>

  <section id="vision">
    <h2 id="vision-title">Digitaler Zwilling &amp; interaktives Schichtenbild</h2>

    <h3 id="vision-video-title">Video: Digitaler Zwilling des klassischen Stacks</h3>
    <p id="vision-video-text">Dieses Video zeigt den klassischen Stack als digitales Haus – von Cloud bis Hardware &amp; Sensorik.</p>
    <video width="100%" controls>
      <source src="DigitalerZwilling.mp4" type="video/mp4" />
      Dein Browser unterstützt das Video-Tag nicht.
    </video>

    <p>
      <a id="vision-youtube-link" href="https://youtu.be/zUHOcTU51rM" target="_blank" rel="noopener noreferrer">
        Video auf YouTube ansehen
      </a>
    </p>

    <hr style="margin:30px 0; border:none; border-top:1px solid #ddd;" />

    <h3 id="vision-stack-title">Interaktives Schichtenbild</h3>
    <p id="vision-stack-text">Bewege die Maus über eine der drei Säulen, um den jeweiligen Ansatz zu erklären.</p>

    <div class="vision-wrapper">
      <div class="vision-stack">
        <!-- Links: klassischer Stack -->
        <div class="vision-column"
             data-title="Klassischer Stack"
             data-description="Viele Schichten, viel Handarbeit: jede Ebene separat modelliert, programmiert und integriert. Hoher Aufwand, aber maximale Kontrolle.">
          <h3 id="vision-col-today">Heute</h3>
          <div class="vision-tagline" id="vision-col-today-tagline">klassischer Stack</div>
          <ul class="layer-list">
            <li>Cloud / Backend</li>
            <li>Edge-Gateway / Middleware</li>
            <li>Robotik-Logik &amp; Regelung</li>
            <li>Firmware (RTOS, Protokolle)</li>
            <li>Hardware &amp; Sensorik</li>
          </ul>
        </div>

        <!-- Mitte: Hybrid -->
        <div class="vision-column"
             style="border-color:#ff8a00; background:linear-gradient(135deg,#fff7ec,#ffe0b8);"
             data-title="Hybrid: Mensch + KI"
             data-description="Embedded, Robotik und KI arbeiten zusammen: KI unterstützt Sensorfusion, Anomalieerkennung und Planung, während Echtzeit und Safety in klaren Schichten bleiben.">
          <h3 id="vision-col-middle">Mitte</h3>
          <div class="vision-tagline" id="vision-col-middle-tagline">Hybrid – Mensch + KI</div>
          <ul class="layer-list">
            <li>Cloud (Training, Flottenanalyse)</li>
            <li>Edge-AI &amp; Koordination</li>
            <li>Robotik-Planung + Controller</li>
            <li>On-Device-ML &amp; Firmware</li>
            <li>Hardware, Aktoren &amp; Sensoren</li>
          </ul>
        </div>

        <!-- Rechts: KI-dominierte Zukunft -->
        <div class="vision-column"
             data-title="KI-dominierte Systeme"
             data-description="Stark automatisierte Pipelines: KI-Agenten übernehmen große Teile von Design, Planung und Steuerung. Effizient, aber mit hohem Bedarf an Erklärbarkeit und Governance.">
          <h3 id="vision-col-future">Zukunft</h3>
          <div class="vision-tagline" id="vision-col-future-tagline">KI-übersteuerter Stack</div>
          <ul class="layer-list">
            <li>End-to-End KI-Orchestrierung</li>
            <li>Auto-Generierung von Code &amp; Tests</li>
            <li>Selbstoptimierende Regelung</li>
            <li>Generische Runtime-Plattform</li>
            <li>Sensoren &amp; Aktoren als „Ressourcen“</li>
          </ul>
        </div>
      </div>
    </div>

    <div class="vision-info" id="vision-info">
      <h3 class="vision-info-title" id="vision-info-title">Hinweis</h3>
      <p class="vision-info-text" id="vision-info-text">
        Fahre mit der Maus über „Heute“, „Mitte“ oder „Zukunft“, um den jeweiligen Ansatz kurz erklärt zu bekommen.
        Das lässt sich in der Präsentation sehr gut live kommentieren.
      </p>
    </div>
  </section>

  <section id="tools">
    <h2 id="tools-title">Tools – KI · Robotik · Embedded</h2>
    <div class="columns">
      <div class="column">
        <span class="badge" id="tools-card1-badge">Embedded-KI</span>
        <h3 id="tools-card1-title">Edge-AI Toolchain (Konzept)</h3>
        <p id="tools-card1-text">
          Pipeline von Datenerfassung über Feature-Engineering bis zur Modellintegration auf Mikrocontrollern
          (z. B. für MedTech, Automotive oder IoT).
        </p>
      </div>
      <div class="column">
        <span class="badge" id="tools-card2-badge">Robotik</span>
        <h3 id="tools-card2-title">Robotik-Stack-Templates</h3>
        <p id="tools-card2-text">
          Vorlagen für Robotik-Anwendungen mit klarer Trennung von Echtzeit-Controllern,
          Bewegungsplanung und KI-gestützter Wahrnehmung.
        </p>
      </div>
      <div class="column">
        <span class="badge" id="tools-card3-badge">Prototyping</span>
        <h3 id="tools-card3-title">Prototyping-Templates</h3>
        <p id="tools-card3-text">
          Projekt-Templates für schnelle Demos – z. B. Zustandsüberwachung, Ganganalyse,
          smarte Aktorik – inklusive Visualisierung und Datenaufzeichnung.
        </p>
      </div>
    </div>
  </section>

  <section id="demos">
    <h2 id="demos-title">Demos – KI in Aktion</h2>
    <p id="demos-intro-text">Beispiele, die sich live zeigen lassen (MedTech, Industrie, Robotik, IoT).</p>

    <!-- Geführte Demo Sensorsohlen -->
    <div class="demo-walkthrough" id="sensor-walkthrough">
      <h3 id="walk-title">Demo: Sensorsohlen – Ganganalyse (6-Schritte-Übersicht)</h3>
      <p id="walk-intro-text" style="font-size:0.9rem;">
        Klicke dich Schritt für Schritt durch das System – von der Produktübersicht über Hardware und Software bis zum fertigen Analysebericht.
      </p>

      <div class="demo-steps">
        <button class="demo-step-btn active" data-step="0">
          <span class="step-number">1</span>
          <span id="step-label-0">Produktübersicht</span>
        </button>
        <button class="demo-step-btn" data-step="1">
          <span class="step-number">2</span>
          <span id="step-label-1">Schaltplan</span>
        </button>
        <button class="demo-step-btn" data-step="2">
          <span class="step-number">3</span>
          <span id="step-label-2">Systemarchitektur</span>
        </button>
        <button class="demo-step-btn" data-step="3">
          <span class="step-number">4</span>
          <span id="step-label-3">Softwarearchitektur</span>
        </button>
        <button class="demo-step-btn" data-step="4">
          <span class="step-number">5</span>
          <span id="step-label-4">Bericht – Übersicht</span>
        </button>
        <button class="demo-step-btn" data-step="5">
          <span class="step-number">6</span>
          <span id="step-label-5">Bericht – Details</span>
        </button>
      </div>

      <div class="demo-content">
        <div class="demo-image-wrapper">
          <img id="demo-image" src="media/sohle_1_produkt.jpeg" alt="Sensorsohlen Produktübersicht" />
        </div>
        <div class="demo-text">
          <h4 id="demo-title">Schritt 1: Produktübersicht</h4>
          <p id="demo-description">
            Die Sensorsohlen bestehen aus zwei Einlagen mit integrierter Elektronik im Kunststoffgehäuse.
            Jede Einlage sitzt zwischen Ferse und Mittelfuß, misst Druckverläufe und Bewegung und kommuniziert per BLE mit der App.
          </p>
        </div>
      </div>
    </div>

    <hr style="margin:30px 0; border:none; border-top:1px solid #ddd;" />

    <!-- Bestehende Demo-Beschreibungen -->
    <h3 id="further-demos-title">Weitere Demo-Ideen</h3>
    <h4 id="further-demo1-title">Ganzheitliche Physio- &amp; Reha-Analyse</h4>
    <ul>
      <li>Sensorsohlen mit Druck- und IMU-Sensoren (Ganganalyse).</li>
      <li>Video- &amp; 3D-Körperanalyse (markerlose Pose-Estimation).</li>
      <li>EMG-Biofeedback für Muskelaktivität und Kompensationsmuster.</li>
      <li>KI-Fusion für Kennzahlen, Alerts und Therapie-Empfehlungen.</li>
    </ul>

    <h4 id="further-demo2-title">KI-Zustandsüberwachung eines Antriebs (Industrie/IoT)</h4>
    <ul>
      <li>Sensorknoten mit IMU, Temperatur und Stromsensor.</li>
      <li>Edge-AI für Merkmalsextraktion und Zustandsbewertung.</li>
      <li>Dashboard-Visualisierung, optional Feldbus/MQTT-Anbindung.</li>
    </ul>
  </section>

  <section id="links">
    <h2 id="links-title">Links – Podcasts, Seiten, Repos</h2>
    <p id="links-intro-text">Struktur für spätere Inhalte (aktuell Platzhalter).</p>
    <div class="columns">
      <div class="column">
        <h3>Podcasts</h3>
        <ul>
          <li>Embedded-Entwicklung &amp; Echtzeit (Platzhalter)</li>
          <li>KI in Industrie &amp; Robotik (Platzhalter)</li>
        </ul>
      </div>
      <div class="column">
        <h3>Webseiten &amp; Blogs</h3>
        <ul>
          <li>Edge-AI / TinyML (Platzhalter)</li>
          <li>Robotik-Architekturen mit KI (Platzhalter)</li>
        </ul>
      </div>
      <div class="column">
        <h3>Repos &amp; Dokus</h3>
        <ul>
          <li>Open-Source-Beispiele für Embedded-KI (Platzhalter)</li>
          <li>Dokumentation zu Toolchains &amp; Frameworks (Platzhalter)</li>
        </ul>
      </div>
    </div>
  </section>

  <section id="events">
    <h2 id="events-title">Events – Konferenzen, Meetups, Schulungen</h2>
    <p id="events-intro-text">Platzhalter für zukünftige Veranstaltungen rund um KI, Robotik und Embedded.</p>
    <ul>
      <li>Embedded-KI-Workshop (Idee).</li>
      <li>Robotik &amp; KI-Demo-Tag (Idee).</li>
      <li>Community-Meetup KI &amp; Embedded (Idee).</li>
    </ul>
  </section>

  <footer>
    © IBSTech Portal – KI · Robotik · Embedded
  </footer>

  <!-- Demo-KI-Agent (einfacher Browser-Chat) -->
  <div class="chat-widget collapsed" id="demo-agent">
    <div class="chat-header" id="chat-header">
      <span>Demo-KI-Agent</span>
      <span class="chat-toggle" id="chat-toggle">▲</span>
    </div>
    <div class="chat-body" id="chat-log">
      <div class="chat-message agent">
        <div class="chat-bubble">
          Hallo, ich bin der Demo-Agent.<br />
          Frag mich z.B. nach <strong>heute</strong>, <strong>hybrid</strong>, <strong>zukunft</strong>,
          oder nach den <strong>Demos</strong> (Physio, Antrieb).
        </div>
      </div>
    </div>
    <div class="chat-input">
      <input type="text" id="chat-input-text" placeholder="Frage eingeben ..." />
      <button id="chat-send">Senden</button>
    </div>
  </div>

  <script>
    // Interaktives Schichtenbild
    (function() {
      var infoBox = document.getElementById('vision-info');
      if (!infoBox) return;
      var titleEl = infoBox.querySelector('.vision-info-title');
      var textEl = infoBox.querySelector('.vision-info-text');
      var columns = document.querySelectorAll('.vision-column');

      columns.forEach(function(col) {
        col.addEventListener('mouseenter', function() {
          var t = col.getAttribute('data-title') || '';
          var d = col.getAttribute('data-description') || '';
          if (t) titleEl.textContent = t;
          if (d) textEl.textContent = d;
        });
        col.setAttribute('tabindex', '0');
        col.addEventListener('focus', function() {
          var t = col.getAttribute('data-title') || '';
          var d = col.getAttribute('data-description') || '';
          if (t) titleEl.textContent = t;
          if (d) textEl.textContent = d;
        });
      });
    })();
  </script>

  <script>
    // Demo-KI-Agent (einfacher Browser-Chat)
    (function() {
      const widget = document.getElementById('demo-agent');
      const toggle = document.getElementById('chat-toggle');
      const header = document.getElementById('chat-header');
      const log = document.getElementById('chat-log');
      const input = document.getElementById('chat-input-text');
      const sendBtn = document.getElementById('chat-send');

      if (!widget || !toggle || !log || !input || !sendBtn || !header) return;

      function toggleChat() {
        widget.classList.toggle('collapsed');
        toggle.textContent = widget.classList.contains('collapsed') ? '▲' : '▼';
      }

      // gesamter Header klickbar
      header.addEventListener('click', toggleChat);

      function appendMessage(text, from) {
        const msg = document.createElement('div');
        msg.className = 'chat-message ' + (from === 'user' ? 'user' : 'agent');
        const bubble = document.createElement('div');
        bubble.className = 'chat-bubble';
        bubble.innerHTML = text;
        msg.appendChild(bubble);
        log.appendChild(msg);
        log.scrollTop = log.scrollHeight;
      }

      function generateAgentAnswer(question) {
        const q = question.toLowerCase();

        if (q.includes('heute') || q.includes('klassisch')) {
          return 'Im klassischen Stack ist alles stark getrennt: Hardware & Sensorik unten, dann Firmware mit RTOS und Protokollen, darüber Robotik-Logik und Regelung, ein Edge-Gateway und ganz oben Cloud/Backend. Viel Handarbeit, aber volle Kontrolle.';
        }
        if (q.includes('hybrid') || q.includes('mitte')) {
          return 'Im Hybrid-Ansatz bleibt die klassische Struktur erhalten, aber einzelne Schichten werden von KI unterstützt – zum Beispiel Sensorfusion, Anomalieerkennung oder Bewegungsplanung. Echtzeit und Safety bleiben klar abgetrennt.';
        }
        if (q.includes('zukunft') || q.includes('ki-domin')) {
          return 'In KI-dominierten Systemen übernehmen KI-Agenten große Teile von Design, Planung und Steuerung. Das kann sehr effizient sein, braucht aber starke Mechanismen für Erklärbarkeit, Safety und Governance.';
        }
        if (q.includes('physio') || q.includes('reha')) {
          return 'Die Physio-/Reha-Demo kombiniert Sensorsohlen, Video- und 3D-Analyse sowie EMG-Biofeedback. Ziel ist eine durchgängige Analyse von Gangbild und Bewegung für Prävention, Assessment und Reha.';
        }
        if (q.includes('antrieb') || q.includes('motor') || q.includes('zustands')) {
          return 'Die Zustandsüberwachungs-Demo nutzt Vibration, Strom und Temperatur an einem Antrieb. Embedded-KI erkennt Abweichungen frühzeitig und kann so auf Wartungsbedarf oder Fehlzustände hinweisen.';
        }
        if (q.includes('multi-agent') || q.includes('agenten')) {
          return 'Multi-Agent-Orchestrierung bedeutet, dass spezialisierte KI-Agenten entlang des V-Modells helfen: bei Anforderungen, Architektur, Code, Tests und Betrieb. Jeder Agent hat eine klare Rolle, der Mensch bleibt in der Verantwortung.';
        }
        if (q.includes('video') || q.includes('digitaler zwilling')) {
          return 'Das Video zeigt den klassischen Stack als digitalen Zwilling in Form eines Hauses – von Cloud/Backend oben bis Hardware & Sensorik unten. Es ist die visuelle Basis, um später Hybrid- und Zukunftsszenarien zu erklären.';
        }

        return 'Ich habe deine Frage verstanden, aber ich bin nur ein einfacher Demo-Agent im Browser. Versuche es mal mit Stichwörtern wie „heute“, „hybrid“, „zukunft“, „Physio“, „Antrieb“ oder „Multi-Agent“.';
      }

      function handleSend() {
        const text = input.value.trim();
        if (!text) return;
        appendMessage(text, 'user');
        input.value = '';

        const answer = generateAgentAnswer(text);
        setTimeout(function() {
          appendMessage(answer, 'agent');
        }, 300);
      }

      sendBtn.addEventListener('click', handleSend);
      input.addEventListener('keydown', function(e) {
        if (e.key === 'Enter') {
          handleSend();
        }
      });
    })();
  </script>

  <script>
    // Mehrsprachigkeit + geführte Sensorsohlen-Demo
    (function() {
      const stepMeta = [
        { img: 'media/sohle_1_produkt.jpeg', key: 'step1' },
        { img: 'media/sohle_2_schaltplan.jpg', key: 'step2' },
        { img: 'media/sohle_3_systemarchitektur.jpg', key: 'step3' },
        { img: 'media/sohle_4_softwarearchitektur.jpg', key: 'step4' },
        { img: 'media/sohle_5_bericht1.png', key: 'step5' },
        { img: 'media/sohle_6_bericht2.png', key: 'step6' }
      ];

      const translations = {
        de: {
          texts: {
            'nav-home-link': 'Home',
            'nav-vision-link': 'Digitaler Zwilling & Schichtenbild',
            'nav-tools-link': 'Tools',
            'nav-demos-link': 'Demos',
            'nav-links-link': 'Links',
            'nav-events-link': 'Events',

            'hero-title': 'IBSTech Portal',
            'hero-tagline': 'KI · Robotik · Embedded',
            'hero-subtitle': 'Digitaler Zwilling und Simulation von KI-, Robotik- und Embedded-Systemen.',
            'btn-vision': 'Digitaler Zwilling & Schichtenbild',
            'btn-demos': 'Demos ansehen',

            'vision-title': 'Digitaler Zwilling & interaktives Schichtenbild',
            'vision-video-title': 'Video: Digitaler Zwilling des klassischen Stacks',
            'vision-video-text': 'Dieses Video zeigt den klassischen Stack als digitales Haus – von Cloud bis Hardware & Sensorik.',
            'vision-youtube-link': 'Video auf YouTube ansehen',
            'vision-stack-title': 'Interaktives Schichtenbild',
            'vision-stack-text': 'Bewege die Maus über eine der drei Säulen, um den jeweiligen Ansatz zu erklären.',
            'vision-col-today': 'Heute',
            'vision-col-today-tagline': 'klassischer Stack',
            'vision-col-middle': 'Mitte',
            'vision-col-middle-tagline': 'Hybrid – Mensch + KI',
            'vision-col-future': 'Zukunft',
            'vision-col-future-tagline': 'KI-übersteuerter Stack',
            'vision-info-title': 'Hinweis',
            'vision-info-text': 'Fahre mit der Maus über „Heute“, „Mitte“ oder „Zukunft“, um den jeweiligen Ansatz kurz erklärt zu bekommen. Das lässt sich in der Präsentation sehr gut live kommentieren.',

            'tools-title': 'Tools – KI · Robotik · Embedded',
            'tools-card1-badge': 'Embedded-KI',
            'tools-card1-title': 'Edge-AI Toolchain (Konzept)',
            'tools-card1-text': 'Pipeline von Datenerfassung über Feature-Engineering bis zur Modellintegration auf Mikrocontrollern (z. B. für MedTech, Automotive oder IoT).',
            'tools-card2-badge': 'Robotik',
            'tools-card2-title': 'Robotik-Stack-Templates',
            'tools-card2-text': 'Vorlagen für Robotik-Anwendungen mit klarer Trennung von Echtzeit-Controllern, Bewegungsplanung und KI-gestützter Wahrnehmung.',
            'tools-card3-badge': 'Prototyping',
            'tools-card3-title': 'Prototyping-Templates',
            'tools-card3-text': 'Projekt-Templates für schnelle Demos – z. B. Zustandsüberwachung, Ganganalyse, smarte Aktorik – inklusive Visualisierung und Datenaufzeichnung.',

            'demos-title': 'Demos – KI in Aktion',
            'demos-intro-text': 'Beispiele, die sich live zeigen lassen (MedTech, Industrie, Robotik, IoT).',
            'walk-title': 'Demo: Sensorsohlen – Ganganalyse (6-Schritte-Übersicht)',
            'walk-intro-text': 'Klicke dich Schritt für Schritt durch das System – von der Produktübersicht über Hardware und Software bis zum fertigen Analysebericht.',

            'step-label-0': 'Produktübersicht',
            'step-label-1': 'Schaltplan',
            'step-label-2': 'Systemarchitektur',
            'step-label-3': 'Softwarearchitektur',
            'step-label-4': 'Bericht – Übersicht',
            'step-label-5': 'Bericht – Details',

            'further-demos-title': 'Weitere Demo-Ideen',
            'further-demo1-title': 'Ganzheitliche Physio- & Reha-Analyse',
            'further-demo2-title': 'KI-Zustandsüberwachung eines Antriebs (Industrie/IoT)',

            'links-title': 'Links – Podcasts, Seiten, Repos',
            'links-intro-text': 'Struktur für spätere Inhalte (aktuell Platzhalter).',

            'events-title': 'Events – Konferenzen, Meetups, Schulungen',
            'events-intro-text': 'Platzhalter für zukünftige Veranstaltungen rund um KI, Robotik und Embedded.'
          },
          steps: {
            step1: {
              label: 'Produktübersicht',
              title: 'Schritt 1: Produktübersicht',
              desc: 'Die Sensorsohlen bestehen aus zwei Einlagen mit integrierter Elektronik im Kunststoffgehäuse. Jede Einlage sitzt zwischen Ferse und Mittelfuß, misst Druckverläufe und Bewegung und kommuniziert per BLE mit der App.'
            },
            step2: {
              label: 'Schaltplan',
              title: 'Schritt 2: Schaltplan der Elektronik',
              desc: 'Der Schaltplan zeigt LiPo-Akku, Schutzschaltung, LDO, MCU mit BLE, IMU sowie mehrere Drucksensoren (FSR) als Spannungsteiler auf ADC-Kanälen. So entsteht die lokale Mess- und Funkplattform in der Sohle.'
            },
            step3: {
              label: 'Systemarchitektur',
              title: 'Schritt 3: Systemarchitektur',
              desc: 'Die Systemarchitektur verbindet die beiden Sensorsohlen über BLE mit der Smartphone-App und weiter mit einem Cloud-/Backend-System. Dort werden Daten gespeichert, analysiert und für Reports aufbereitet.'
            },
            step4: {
              label: 'Softwarearchitektur',
              title: 'Schritt 4: Softwarearchitektur',
              desc: 'Die Softwarearchitektur zeigt die Ebenen von der Firmware auf der Sohle (Treiber, RTOS, Messlogik) über BLE-Protokoll und Smartphone-App (UI, Domain-Logik) bis hin zur Analyse-Engine und dem Report-Generator im Backend.'
            },
            step5: {
              label: 'Bericht – Übersicht',
              title: 'Schritt 5: Analysebericht – Übersicht',
              desc: 'Der erste Berichtsscreen zeigt die wichtigsten Kennzahlen wie Symmetrie, Cadence und Speed sowie aggregierte Bewertungen. Er dient als schneller Überblick für Nutzer und Therapeuten.'
            },
            step6: {
              label: 'Bericht – Details',
              title: 'Schritt 6: Analysebericht – Details',
              desc: 'Im Detailbericht werden zusätzliche Parameter wie Gait Line, Pronation/Supination, Belastungsverläufe und Clearance visualisiert. Das erlaubt eine tiefergehende Interpretation des Gangbilds.'
            }
          }
        },

        en: {
          texts: {
            'nav-home-link': 'Home',
            'nav-vision-link': 'Digital twin & layer view',
            'nav-tools-link': 'Tools',
            'nav-demos-link': 'Demos',
            'nav-links-link': 'Links',
            'nav-events-link': 'Events',

            'hero-title': 'IBSTech Portal',
            'hero-tagline': 'AI · Robotics · Embedded',
            'hero-subtitle': 'Digital twin and simulation of AI, robotics and embedded systems.',
            'btn-vision': 'Digital twin & layer view',
            'btn-demos': 'View demos',

            'vision-title': 'Digital twin & interactive layer model',
            'vision-video-title': 'Video: Digital twin of the classic stack',
            'vision-video-text': 'This video shows the classic stack as a digital house – from cloud down to hardware & sensors.',
            'vision-youtube-link': 'Watch video on YouTube',
            'vision-stack-title': 'Interactive layer view',
            'vision-stack-text': 'Move the mouse over one of the three pillars to see the respective approach explained.',
            'vision-col-today': 'Today',
            'vision-col-today-tagline': 'classic stack',
            'vision-col-middle': 'Middle',
            'vision-col-middle-tagline': 'Hybrid – human + AI',
            'vision-col-future': 'Future',
            'vision-col-future-tagline': 'AI-driven stack',
            'vision-info-title': 'Hint',
            'vision-info-text': 'Hover over “Today”, “Middle” or “Future” to get a short explanation of each approach. This works very well for live commentary in your presentation.',

            'tools-title': 'Tools – AI · Robotics · Embedded',
            'tools-card1-badge': 'Embedded AI',
            'tools-card1-title': 'Edge-AI toolchain (concept)',
            'tools-card1-text': 'Pipeline from data acquisition and feature engineering to model integration on microcontrollers (e.g. for MedTech, automotive or IoT).',
            'tools-card2-badge': 'Robotics',
            'tools-card2-title': 'Robotics stack templates',
            'tools-card2-text': 'Templates for robotics applications with a clear separation between real-time controllers, motion planning and AI-based perception.',
            'tools-card3-badge': 'Prototyping',
            'tools-card3-title': 'Prototyping templates',
            'tools-card3-text': 'Project templates for fast demos – e.g. condition monitoring, gait analysis, smart actuators – including visualization and data logging.',

            'demos-title': 'Demos – AI in action',
            'demos-intro-text': 'Examples that can be shown live (MedTech, industry, robotics, IoT).',
            'walk-title': 'Demo: sensor insoles – gait analysis (6-step overview)',
            'walk-intro-text': 'Click through the system step by step – from product overview via hardware and software to the final analysis report.',

            'step-label-0': 'Product overview',
            'step-label-1': 'Schematic',
            'step-label-2': 'System architecture',
            'step-label-3': 'Software architecture',
            'step-label-4': 'Report – overview',
            'step-label-5': 'Report – details',

            'further-demos-title': 'Additional demo ideas',
            'further-demo1-title': 'Holistic physio & rehab analysis',
            'further-demo2-title': 'AI-based drive condition monitoring (industry/IoT)',

            'links-title': 'Links – podcasts, pages, repos',
            'links-intro-text': 'Structure for future content (currently placeholders).',

            'events-title': 'Events – conferences, meetups, trainings',
            'events-intro-text': 'Placeholder for future events around AI, robotics and embedded.'
          },
          steps: {
            step1: {
              label: 'Product overview',
              title: 'Step 1: Product overview',
              desc: 'The sensor insoles consist of two inserts with integrated electronics in a plastic housing. Each insert sits between heel and midfoot, measures pressure patterns and motion, and communicates via BLE with the app.'
            },
            step2: {
              label: 'Schematic',
              title: 'Step 2: Electronics schematic',
              desc: 'The schematic shows LiPo battery, protection circuit, LDO, MCU with BLE, IMU and multiple pressure sensors (FSR) as voltage dividers on ADC channels. This forms the local measurement and radio platform inside the insole.'
            },
            step3: {
              label: 'System architecture',
              title: 'Step 3: System architecture',
              desc: 'The system architecture connects both sensor insoles via BLE to the smartphone app and further to a cloud/backend system. Data is stored, analysed and prepared for reports there.'
            },
            step4: {
              label: 'Software architecture',
              title: 'Step 4: Software architecture',
              desc: 'The software architecture spans from firmware on the insole (drivers, RTOS, measurement logic) via BLE protocol and smartphone app (UI, domain logic) up to the analytics engine and report generator in the backend.'
            },
            step5: {
              label: 'Report – overview',
              title: 'Step 5: Analysis report – overview',
              desc: 'The first report screen shows key metrics such as symmetry, cadence and speed plus aggregated ratings. It provides a quick overview for users and therapists.'
            },
            step6: {
              label: 'Report – details',
              title: 'Step 6: Analysis report – details',
              desc: 'The detailed report visualises additional parameters such as gait line, pronation/supination, load curves and clearance. This enables deeper interpretation of the gait pattern.'
            }
          }
        },

        fr: {
          texts: {
            'nav-home-link': 'Accueil',
            'nav-vision-link': 'Jumeau numérique & couches',
            'nav-tools-link': 'Outils',
            'nav-demos-link': 'Démos',
            'nav-links-link': 'Liens',
            'nav-events-link': 'Événements',

            'hero-title': 'IBSTech Portal',
            'hero-tagline': 'IA · Robotique · Embarqué',
            'hero-subtitle': 'Jumeau numérique et simulation de systèmes IA, robotiques et embarqués.',
            'btn-vision': 'Jumeau numérique & couches',
            'btn-demos': 'Voir les démos',

            'vision-title': 'Jumeau numérique & vue en couches interactive',
            'vision-video-title': 'Vidéo : jumeau numérique de la pile classique',
            'vision-video-text': 'Cette vidéo montre la pile classique sous forme de maison numérique – du cloud jusqu’au matériel et aux capteurs.',
            'vision-youtube-link': 'Voir la vidéo sur YouTube',
            'vision-stack-title': 'Vue en couches interactive',
            'vision-stack-text': 'Survolez l’une des trois colonnes pour voir l’approche correspondante expliquée.',
            'vision-col-today': 'Aujourd’hui',
            'vision-col-today-tagline': 'pile classique',
            'vision-col-middle': 'Milieu',
            'vision-col-middle-tagline': 'Hybride – humain + IA',
            'vision-col-future': 'Futur',
            'vision-col-future-tagline': 'Pile pilotée par l’IA',
            'vision-info-title': 'Remarque',
            'vision-info-text': 'Survolez « Aujourd’hui », « Milieu » ou « Futur » pour obtenir une courte explication de chaque approche. Idéal à commenter en direct pendant la présentation.',

            'tools-title': 'Outils – IA · Robotique · Embarqué',
            'tools-card1-badge': 'IA embarquée',
            'tools-card1-title': 'Toolchain Edge-AI (concept)',
            'tools-card1-text': 'Pipeline allant de l’acquisition des données et l’ingénierie des caractéristiques jusqu’à l’intégration du modèle sur microcontrôleurs (p. ex. pour MedTech, automobile ou IoT).',
            'tools-card2-badge': 'Robotique',
            'tools-card2-title': 'Templates de pile robotique',
            'tools-card2-text': 'Modèles pour des applications robotiques avec séparation claire entre contrôle temps réel, planification de mouvement et perception basée sur l’IA.',
            'tools-card3-badge': 'Prototypage',
            'tools-card3-title': 'Templates de prototypage',
            'tools-card3-text': 'Templates de projet pour des démos rapides – p. ex. surveillance d’état, analyse de marche, actionneurs intelligents – y compris visualisation et enregistrement des données.',

            'demos-title': 'Démos – l’IA en action',
            'demos-intro-text': 'Exemples à montrer en direct (MedTech, industrie, robotique, IoT).',
            'walk-title': 'Démo : semelles capteurs – analyse de marche (vue en 6 étapes)',
            'walk-intro-text': 'Parcourez le système étape par étape – de la vue produit au matériel et logiciel jusqu’au rapport d’analyse final.',

            'step-label-0': 'Vue produit',
            'step-label-1': 'Schéma',
            'step-label-2': 'Architecture système',
            'step-label-3': 'Architecture logicielle',
            'step-label-4': 'Rapport – vue d’ensemble',
            'step-label-5': 'Rapport – détails',

            'further-demos-title': 'Autres idées de démos',
            'further-demo1-title': 'Analyse physio & rééducation globale',
            'further-demo2-title': 'Surveillance d’état de moteur par IA (industrie/IoT)',

            'links-title': 'Liens – podcasts, sites, repos',
            'links-intro-text': 'Structure pour du contenu futur (pour l’instant des espaces réservés).',

            'events-title': 'Événements – conférences, meetups, formations',
            'events-intro-text': 'Espace réservé pour de futurs événements autour de l’IA, de la robotique et de l’embarqué.'
          },
          steps: {
            step1: {
              label: 'Vue produit',
              title: 'Étape 1 : vue produit',
              desc: 'Les semelles capteurs se composent de deux inserts avec électronique intégrée dans un boîtier plastique. Chaque insert se trouve entre le talon et le médio-pied, mesure les profils de pression et le mouvement et communique en BLE avec l’application.'
            },
            step2: {
              label: 'Schéma',
              title: 'Étape 2 : schéma électronique',
              desc: 'Le schéma montre une batterie LiPo, un circuit de protection, un LDO, un MCU avec BLE, une IMU ainsi que plusieurs capteurs de pression (FSR) en diviseurs de tension sur des entrées ADC. Cela forme la plateforme locale de mesure et de radio dans la semelle.'
            },
            step3: {
              label: 'Architecture système',
              title: 'Étape 3 : architecture système',
              desc: 'L’architecture système relie les deux semelles capteurs via BLE à l’application smartphone puis à un backend/cloud. Les données y sont stockées, analysées et préparées pour les rapports.'
            },
            step4: {
              label: 'Architecture logicielle',
              title: 'Étape 4 : architecture logicielle',
              desc: 'L’architecture logicielle couvre le firmware sur la semelle (drivers, RTOS, logique de mesure), le protocole BLE et l’application smartphone (UI, logique métier) jusqu’au moteur d’analyse et au générateur de rapports dans le backend.'
            },
            step5: {
              label: 'Rapport – vue d’ensemble',
              title: 'Étape 5 : rapport d’analyse – vue d’ensemble',
              desc: 'Le premier écran de rapport affiche les principaux indicateurs comme la symétrie, la cadence et la vitesse ainsi que des évaluations agrégées. Il fournit une vue rapide pour les utilisateurs et les thérapeutes.'
            },
            step6: {
              label: 'Rapport – détails',
              title: 'Étape 6 : rapport d’analyse – détails',
              desc: 'Le rapport détaillé visualise des paramètres supplémentaires comme la ligne de marche, la pronation/supination, les courbes de charge et la clearance. Cela permet une interprétation plus approfondie de la marche.'
            }
          }
        },

        es: {
          texts: {
            'nav-home-link': 'Inicio',
            'nav-vision-link': 'Gemelo digital y capas',
            'nav-tools-link': 'Herramientas',
            'nav-demos-link': 'Demos',
            'nav-links-link': 'Enlaces',
            'nav-events-link': 'Eventos',

            'hero-title': 'IBSTech Portal',
            'hero-tagline': 'IA · Robótica · Embebido',
            'hero-subtitle': 'Gemelo digital y simulación de sistemas de IA, robótica y embebidos.',
            'btn-vision': 'Gemelo digital y capas',
            'btn-demos': 'Ver demos',

            'vision-title': 'Gemelo digital y vista por capas interactiva',
            'vision-video-title': 'Vídeo: gemelo digital del stack clásico',
            'vision-video-text': 'Este vídeo muestra el stack clásico como una casa digital, desde la nube hasta el hardware y los sensores.',
            'vision-youtube-link': 'Ver vídeo en YouTube',
            'vision-stack-title': 'Vista por capas interactiva',
            'vision-stack-text': 'Mueve el ratón sobre una de las tres columnas para ver explicada cada aproximación.',
            'vision-col-today': 'Hoy',
            'vision-col-today-tagline': 'stack clásico',
            'vision-col-middle': 'Centro',
            'vision-col-middle-tagline': 'Híbrido – humano + IA',
            'vision-col-future': 'Futuro',
            'vision-col-future-tagline': 'Stack dirigido por IA',
            'vision-info-title': 'Nota',
            'vision-info-text': 'Pasa el ratón por «Hoy», «Centro» o «Futuro» para obtener una breve explicación de cada enfoque. Es ideal para comentarlo en directo durante la presentación.',

            'tools-title': 'Herramientas – IA · Robótica · Embebido',
            'tools-card1-badge': 'IA embebida',
            'tools-card1-title': 'Toolchain de Edge-AI (concepto)',
            'tools-card1-text': 'Pipeline desde la adquisición de datos y el diseño de características hasta la integración del modelo en microcontroladores (p. ej. para MedTech, automoción o IoT).',
            'tools-card2-badge': 'Robótica',
            'tools-card2-title': 'Plantillas de stack robótico',
            'tools-card2-text': 'Modelos para aplicaciones robóticas con clara separación entre control en tiempo real, planificación de movimiento y percepción basada en IA.',
            'tools-card3-badge': 'Prototipado',
            'tools-card3-title': 'Plantillas de prototipado',
            'tools-card3-text': 'Plantillas de proyecto para demos rápidas – p. ej. monitorización de estado, análisis de la marcha, actuadores inteligentes – con visualización y registro de datos.',

            'demos-title': 'Demos – IA en acción',
            'demos-intro-text': 'Ejemplos que se pueden mostrar en directo (MedTech, industria, robótica, IoT).',
            'walk-title': 'Demo: plantillas sensoras – análisis de la marcha (vista en 6 pasos)',
            'walk-intro-text': 'Recorre el sistema paso a paso: desde la vista del producto, pasando por hardware y software, hasta el informe de análisis final.',

            'step-label-0': 'Vista del producto',
            'step-label-1': 'Esquema',
            'step-label-2': 'Arquitectura del sistema',
            'step-label-3': 'Arquitectura de software',
            'step-label-4': 'Informe – resumen',
            'step-label-5': 'Informe – detalles',

            'further-demos-title': 'Más ideas de demos',
            'further-demo1-title': 'Análisis global de fisio y rehabilitación',
            'further-demo2-title': 'Monitorización de estado de un accionamiento con IA (industria/IoT)',

            'links-title': 'Enlaces – podcasts, sitios, repos',
            'links-intro-text': 'Estructura para contenido futuro (de momento marcadores de posición).',

            'events-title': 'Eventos – conferencias, meetups, formaciones',
            'events-intro-text': 'Marcador de posición para futuros eventos sobre IA, robótica y embebidos.'
          },
          steps: {
            step1: {
              label: 'Vista del producto',
              title: 'Paso 1: vista del producto',
              desc: 'Las plantillas sensoras constan de dos plantillas con electrónica integrada en una carcasa de plástico. Cada plantilla se sitúa entre el talón y el mediopié, mide patrones de presión y movimiento y se comunica por BLE con la app.'
            },
            step2: {
              label: 'Esquema',
              title: 'Paso 2: esquema electrónico',
              desc: 'El esquema muestra una batería LiPo, circuito de protección, LDO, MCU con BLE, IMU y varios sensores de presión (FSR) como divisores de tensión en canales ADC. Esto forma la plataforma local de medida y radio dentro de la plantilla.'
            },
            step3: {
              label: 'Arquitectura del sistema',
              title: 'Paso 3: arquitectura del sistema',
              desc: 'La arquitectura del sistema conecta las dos plantillas sensoras mediante BLE con la app del smartphone y después con un sistema backend/nube. Allí se almacenan, analizan y preparan los datos para los informes.'
            },
            step4: {
              label: 'Arquitectura de software',
              title: 'Paso 4: arquitectura de software',
              desc: 'La arquitectura de software cubre el firmware en la plantilla (drivers, RTOS, lógica de medida), el protocolo BLE y la app del smartphone (UI, lógica de dominio) hasta el motor de analítica y el generador de informes en el backend.'
            },
            step5: {
              label: 'Informe – resumen',
              title: 'Paso 5: informe de análisis – resumen',
              desc: 'La primera pantalla del informe muestra métricas clave como simetría, cadencia y velocidad, además de valoraciones agregadas. Ofrece una visión rápida para usuarios y terapeutas.'
            },
            step6: {
              label: 'Informe – detalles',
              title: 'Paso 6: informe de análisis – detalles',
              desc: 'El informe detallado visualiza parámetros adicionales como línea de marcha, pronación/supinación, curvas de carga y clearance. Esto permite una interpretación más profunda del patrón de marcha.'
            }
          }
        }
      };

      let currentLang = 'de';
      let currentStepIndex = 0;

      const imgEl = document.getElementById('demo-image');
      const titleEl = document.getElementById('demo-title');
      const descEl = document.getElementById('demo-description');
      const buttons = document.querySelectorAll('.demo-step-btn');

      function setStep(index) {
        const meta = stepMeta[index];
        if (!meta) return;
        const dictSteps = translations[currentLang].steps;
        const stepTexts = dictSteps[meta.key];
        imgEl.src = meta.img;
        imgEl.alt = stepTexts.title;
        titleEl.textContent = stepTexts.title;
        descEl.textContent = stepTexts.desc;

        buttons.forEach(btn => btn.classList.remove('active'));
        const active = Array.from(buttons).find(b => Number(b.getAttribute('data-step')) === index);
        if (active) active.classList.add('active');

        currentStepIndex = index;
      }

      buttons.forEach(btn => {
        btn.addEventListener('click', () => {
          const index = Number(btn.getAttribute('data-step'));
          setStep(index);
        });
      });

      function applyTranslations() {
        const dict = translations[currentLang];
        if (!dict) return;

        // statische Texte
        Object.keys(dict.texts).forEach(id => {
          const el = document.getElementById(id);
          if (el) {
            el.textContent = dict.texts[id];
          }
        });

        // Schritt-Labels
        stepMeta.forEach((meta, idx) => {
          const labelEl = document.getElementById('step-label-' + idx);
          if (!labelEl) return;
          const stepTexts = dict.steps[meta.key];
          labelEl.textContent = stepTexts.label;
        });

        // Sprache im <html>-Tag setzen
        document.documentElement.lang = currentLang;

        // Aktiven Button markieren
        document.querySelectorAll('.lang-btn').forEach(btn => {
          btn.classList.toggle('active', btn.getAttribute('data-lang') === currentLang);
        });

        // aktuellen Schritt-Text aktualisieren
        setStep(currentStepIndex);
      }

      // Sprachbuttons
      document.querySelectorAll('.lang-btn').forEach(btn => {
        btn.addEventListener('click', () => {
          const lang = btn.getAttribute('data-lang');
          if (!translations[lang]) return;
          currentLang = lang;
          applyTranslations();
        });
      });

      // Initiale Sprache anwenden
      applyTranslations();
    })();
  </script>

</body>
</html>
